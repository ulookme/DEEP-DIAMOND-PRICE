{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d25777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import pickle\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from imblearn.over_sampling import ADASYN\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTEENN\n",
    "# data processing\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "from keras.layers import Flatten\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#import sweetviz as sv\n",
    "# Import Modules\n",
    "import datetime\n",
    "import itertools\n",
    "import graphviz\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Keras, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \\\n",
    "    , fbeta_score, classification_report, confusion_matrix, precision_recall_curve, roc_auc_score \\\n",
    "    , roc_curve\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, Masking, TimeDistributed\n",
    "from tensorflow. keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c543315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTATION DES DONNEES enygma\n",
    "df = pd.read_csv('diamant_cc2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d37043f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>326</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>2.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>326</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>2.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.900000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>327</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>2.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.290000</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>334</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>2.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.300000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>335</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173698</th>\n",
       "      <td>1.011745</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.095414</td>\n",
       "      <td>56.908280</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.442115</td>\n",
       "      <td>6.414408</td>\n",
       "      <td>3.989452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173699</th>\n",
       "      <td>1.011366</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.095203</td>\n",
       "      <td>56.904067</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.441293</td>\n",
       "      <td>6.413691</td>\n",
       "      <td>3.988968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173700</th>\n",
       "      <td>1.012589</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.095883</td>\n",
       "      <td>56.917657</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.443943</td>\n",
       "      <td>6.416002</td>\n",
       "      <td>3.990531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173701</th>\n",
       "      <td>1.012336</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.095742</td>\n",
       "      <td>56.914841</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.443394</td>\n",
       "      <td>6.415523</td>\n",
       "      <td>3.990207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173702</th>\n",
       "      <td>1.011526</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.095292</td>\n",
       "      <td>56.905842</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.441639</td>\n",
       "      <td>6.413993</td>\n",
       "      <td>3.989172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173703 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat      cut color clarity      depth      table  price  \\\n",
       "0       0.230000    Ideal     E     SI2  61.500000  55.000000    326   \n",
       "1       0.210000  Premium     E     SI1  59.800000  61.000000    326   \n",
       "2       0.230000     Good     E     VS1  56.900000  65.000000    327   \n",
       "3       0.290000  Premium     I     VS2  62.400000  58.000000    334   \n",
       "4       0.310000     Good     J     SI2  63.300000  58.000000    335   \n",
       "...          ...      ...   ...     ...        ...        ...    ...   \n",
       "173698  1.011745    Ideal     I    VVS1  62.095414  56.908280   3936   \n",
       "173699  1.011366    Ideal     I    VVS1  62.095203  56.904067   3936   \n",
       "173700  1.012589    Ideal     I    VVS1  62.095883  56.917657   3936   \n",
       "173701  1.012336    Ideal     I    VVS1  62.095742  56.914841   3936   \n",
       "173702  1.011526    Ideal     I    VVS1  62.095292  56.905842   3936   \n",
       "\n",
       "               x         y         z  \n",
       "0       3.950000  3.980000  2.430000  \n",
       "1       3.890000  3.840000  2.310000  \n",
       "2       4.050000  4.070000  2.310000  \n",
       "3       4.200000  4.230000  2.630000  \n",
       "4       4.340000  4.350000  2.750000  \n",
       "...          ...       ...       ...  \n",
       "173698  6.442115  6.414408  3.989452  \n",
       "173699  6.441293  6.413691  3.988968  \n",
       "173700  6.443943  6.416002  3.990531  \n",
       "173701  6.443394  6.415523  3.990207  \n",
       "173702  6.441639  6.413993  3.989172  \n",
       "\n",
       "[173703 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9cc9585",
   "metadata": {},
   "source": [
    "df.cut.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51557a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SI1     47615\n",
       "SI2     37240\n",
       "VS1     25031\n",
       "VS2     22318\n",
       "IF      16878\n",
       "VVS1    12506\n",
       "VVS2     6180\n",
       "I1       5935\n",
       "Name: clarity, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baa128fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_cla = preprocessing.LabelEncoder()\n",
    "le_cut = preprocessing.LabelEncoder()\n",
    "le_color = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fafcf95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clarity']= le_cla.fit_transform(df['clarity'])\n",
    "df['cut']= le_cut.fit_transform(df['cut'])\n",
    "df['color']= le_color.fit_transform(df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf961843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>326</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>2.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>326</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>2.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>56.900000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>327</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>2.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.290000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>334</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>2.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>63.300000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>335</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173698</th>\n",
       "      <td>1.011745</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095414</td>\n",
       "      <td>56.908280</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.442115</td>\n",
       "      <td>6.414408</td>\n",
       "      <td>3.989452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173699</th>\n",
       "      <td>1.011366</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095203</td>\n",
       "      <td>56.904067</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.441293</td>\n",
       "      <td>6.413691</td>\n",
       "      <td>3.988968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173700</th>\n",
       "      <td>1.012589</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095883</td>\n",
       "      <td>56.917657</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.443943</td>\n",
       "      <td>6.416002</td>\n",
       "      <td>3.990531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173701</th>\n",
       "      <td>1.012336</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095742</td>\n",
       "      <td>56.914841</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.443394</td>\n",
       "      <td>6.415523</td>\n",
       "      <td>3.990207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173702</th>\n",
       "      <td>1.011526</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095292</td>\n",
       "      <td>56.905842</td>\n",
       "      <td>3936</td>\n",
       "      <td>6.441639</td>\n",
       "      <td>6.413993</td>\n",
       "      <td>3.989172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173703 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat  cut  color  clarity      depth      table  price         x  \\\n",
       "0       0.230000    2      1        3  61.500000  55.000000    326  3.950000   \n",
       "1       0.210000    3      1        2  59.800000  61.000000    326  3.890000   \n",
       "2       0.230000    1      1        4  56.900000  65.000000    327  4.050000   \n",
       "3       0.290000    3      5        5  62.400000  58.000000    334  4.200000   \n",
       "4       0.310000    1      6        3  63.300000  58.000000    335  4.340000   \n",
       "...          ...  ...    ...      ...        ...        ...    ...       ...   \n",
       "173698  1.011745    2      5        6  62.095414  56.908280   3936  6.442115   \n",
       "173699  1.011366    2      5        6  62.095203  56.904067   3936  6.441293   \n",
       "173700  1.012589    2      5        6  62.095883  56.917657   3936  6.443943   \n",
       "173701  1.012336    2      5        6  62.095742  56.914841   3936  6.443394   \n",
       "173702  1.011526    2      5        6  62.095292  56.905842   3936  6.441639   \n",
       "\n",
       "               y         z  \n",
       "0       3.980000  2.430000  \n",
       "1       3.840000  2.310000  \n",
       "2       4.070000  2.310000  \n",
       "3       4.230000  2.630000  \n",
       "4       4.350000  2.750000  \n",
       "...          ...       ...  \n",
       "173698  6.414408  3.989452  \n",
       "173699  6.413691  3.988968  \n",
       "173700  6.416002  3.990531  \n",
       "173701  6.415523  3.990207  \n",
       "173702  6.413993  3.989172  \n",
       "\n",
       "[173703 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ff9149c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    37928\n",
       "2    35332\n",
       "1    32172\n",
       "4    27255\n",
       "0    20854\n",
       "5    15556\n",
       "6     4606\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ee794ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =  pd.DataFrame(\n",
    "        data=df,\n",
    "        columns=[\n",
    "            \"carat\",\n",
    "            \"cut\",\n",
    "            \"color\",\n",
    "            \"clarity\",\n",
    "            \"depth\",\n",
    "            \"table\",\n",
    "            \"x\",\n",
    "            \"y\",\n",
    "            \"z\",\n",
    "            \"price\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0082e086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>2.310000</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>56.900000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>2.310000</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.290000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>63.300000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173698</th>\n",
       "      <td>1.011745</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095414</td>\n",
       "      <td>56.908280</td>\n",
       "      <td>6.442115</td>\n",
       "      <td>6.414408</td>\n",
       "      <td>3.989452</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173699</th>\n",
       "      <td>1.011366</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095203</td>\n",
       "      <td>56.904067</td>\n",
       "      <td>6.441293</td>\n",
       "      <td>6.413691</td>\n",
       "      <td>3.988968</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173700</th>\n",
       "      <td>1.012589</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095883</td>\n",
       "      <td>56.917657</td>\n",
       "      <td>6.443943</td>\n",
       "      <td>6.416002</td>\n",
       "      <td>3.990531</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173701</th>\n",
       "      <td>1.012336</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095742</td>\n",
       "      <td>56.914841</td>\n",
       "      <td>6.443394</td>\n",
       "      <td>6.415523</td>\n",
       "      <td>3.990207</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173702</th>\n",
       "      <td>1.011526</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>62.095292</td>\n",
       "      <td>56.905842</td>\n",
       "      <td>6.441639</td>\n",
       "      <td>6.413993</td>\n",
       "      <td>3.989172</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173703 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat  cut  color  clarity      depth      table         x  \\\n",
       "0       0.230000    2      1        3  61.500000  55.000000  3.950000   \n",
       "1       0.210000    3      1        2  59.800000  61.000000  3.890000   \n",
       "2       0.230000    1      1        4  56.900000  65.000000  4.050000   \n",
       "3       0.290000    3      5        5  62.400000  58.000000  4.200000   \n",
       "4       0.310000    1      6        3  63.300000  58.000000  4.340000   \n",
       "...          ...  ...    ...      ...        ...        ...       ...   \n",
       "173698  1.011745    2      5        6  62.095414  56.908280  6.442115   \n",
       "173699  1.011366    2      5        6  62.095203  56.904067  6.441293   \n",
       "173700  1.012589    2      5        6  62.095883  56.917657  6.443943   \n",
       "173701  1.012336    2      5        6  62.095742  56.914841  6.443394   \n",
       "173702  1.011526    2      5        6  62.095292  56.905842  6.441639   \n",
       "\n",
       "               y         z  price  \n",
       "0       3.980000  2.430000    326  \n",
       "1       3.840000  2.310000    326  \n",
       "2       4.070000  2.310000    327  \n",
       "3       4.230000  2.630000    334  \n",
       "4       4.350000  2.750000    335  \n",
       "...          ...       ...    ...  \n",
       "173698  6.414408  3.989452   3936  \n",
       "173699  6.413691  3.988968   3936  \n",
       "173700  6.416002  3.990531   3936  \n",
       "173701  6.415523  3.990207   3936  \n",
       "173702  6.413993  3.989172   3936  \n",
       "\n",
       "[173703 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2382f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = shuffle(df2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "220c2f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156332, 10) (17371, 10)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df2) * 0.90)\n",
    "test_size = len(df2) - train_size\n",
    "train, test = df2.iloc[0:train_size], df2.iloc[train_size:len(df2)]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b9ecfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train.values[:, 0:9])\n",
    "y_train = np.array(train.values[:, -1])\n",
    "X_test = np.array(test.values[:, 0:9])\n",
    "y_test = np.array(test.values[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70711734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle save path /Users/charleshajjar/Desktop/PROJET_DIAMANT/scaler2.pickle\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train= scaler2.transform(X_train)\n",
    "X_test = scaler2.transform(X_test)\n",
    "\n",
    "save_path = os.path.join('/Users/charleshajjar/Desktop/PROJET_DIAMANT', 'scaler2.pickle')\n",
    "print('Pickle save path', save_path)\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(scaler2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e338adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X, y):\n",
    "    \"\"\"\n",
    "    TODO commenter\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # create model\n",
    "    #####################################################################################################    \n",
    "    # Constructing the CNN & training \n",
    "    # Select the type of the model\n",
    "    # Add the first Dense layer with 30 neuron units and ReLu activation function\n",
    "    model = keras.models.Sequential([\n",
    "    keras.layers.Dense(60, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_dim=9),\n",
    "    keras.layers.Dense(units=10,\n",
    "                kernel_initializer='lecun_normal',\n",
    "                activation='selu'),\n",
    "        \n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "    print('Model summary', model.summary())\n",
    "    \n",
    "    # learning rate optimizer exponentialDecay\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "    #optimizer Adam low learning rate O,1 and exponentiel\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    # optimizer Adam  UpPer\n",
    "    # Training 1\n",
    "    #opt = keras.optimizers.Adam(learning_rate=0.09)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "    model.fit(\n",
    "        X_train, y_train, epochs=500, batch_size=100, validation_split=0.1\n",
    "    )\n",
    "    model.save('PRICESTIANE1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5452cb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ufunc 'exp'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "004c53c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                600       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                610       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,221\n",
      "Trainable params: 1,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model summary None\n",
      "Epoch 1/500\n",
      "1407/1407 [==============================] - 2s 886us/step - loss: 7514251.5739 - mae: 1822.8676 - val_loss: 1032579.8125 - val_mae: 661.9469\n",
      "Epoch 2/500\n",
      "1407/1407 [==============================] - 1s 730us/step - loss: 953664.4062 - mae: 635.7900 - val_loss: 864916.3125 - val_mae: 568.9881\n",
      "Epoch 3/500\n",
      "1407/1407 [==============================] - 1s 729us/step - loss: 758071.4973 - mae: 538.2691 - val_loss: 706934.2500 - val_mae: 492.8332\n",
      "Epoch 4/500\n",
      "1407/1407 [==============================] - 1s 805us/step - loss: 671906.6862 - mae: 483.8112 - val_loss: 646531.1250 - val_mae: 470.5527\n",
      "Epoch 5/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 594138.0716 - mae: 457.3262 - val_loss: 598533.6250 - val_mae: 447.9832\n",
      "Epoch 6/500\n",
      "1407/1407 [==============================] - 1s 803us/step - loss: 558430.3781 - mae: 441.9449 - val_loss: 583426.1250 - val_mae: 440.2253\n",
      "Epoch 7/500\n",
      "1407/1407 [==============================] - 1s 749us/step - loss: 560983.6829 - mae: 439.3873 - val_loss: 572643.2500 - val_mae: 434.0626\n",
      "Epoch 8/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 548835.8139 - mae: 436.5989 - val_loss: 563690.8750 - val_mae: 429.4781\n",
      "Epoch 9/500\n",
      "1407/1407 [==============================] - 1s 784us/step - loss: 541095.0572 - mae: 435.2220 - val_loss: 573678.8750 - val_mae: 440.1793\n",
      "Epoch 10/500\n",
      "1407/1407 [==============================] - 1s 743us/step - loss: 535369.1827 - mae: 430.4547 - val_loss: 555720.3750 - val_mae: 436.7182\n",
      "Epoch 11/500\n",
      "1407/1407 [==============================] - 1s 734us/step - loss: 531589.1002 - mae: 427.2646 - val_loss: 544533.5625 - val_mae: 422.6714\n",
      "Epoch 12/500\n",
      "1407/1407 [==============================] - 1s 878us/step - loss: 514919.8432 - mae: 422.6063 - val_loss: 538910.1250 - val_mae: 426.5510\n",
      "Epoch 13/500\n",
      "1407/1407 [==============================] - 1s 755us/step - loss: 517521.3354 - mae: 423.5112 - val_loss: 527158.5000 - val_mae: 420.5954\n",
      "Epoch 14/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 510120.8713 - mae: 418.6077 - val_loss: 519212.3125 - val_mae: 419.8999\n",
      "Epoch 15/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 511807.0012 - mae: 419.8466 - val_loss: 517125.0312 - val_mae: 415.1335\n",
      "Epoch 16/500\n",
      "1407/1407 [==============================] - 1s 725us/step - loss: 505470.7674 - mae: 418.7014 - val_loss: 511622.2188 - val_mae: 413.8523\n",
      "Epoch 17/500\n",
      "1407/1407 [==============================] - 1s 715us/step - loss: 507372.1008 - mae: 414.7339 - val_loss: 511746.2500 - val_mae: 417.1473\n",
      "Epoch 18/500\n",
      "1407/1407 [==============================] - 1s 715us/step - loss: 495221.1304 - mae: 413.5699 - val_loss: 508768.6250 - val_mae: 412.6930\n",
      "Epoch 19/500\n",
      "1407/1407 [==============================] - 1s 724us/step - loss: 501221.0164 - mae: 413.2386 - val_loss: 502049.2812 - val_mae: 412.4628\n",
      "Epoch 20/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 490315.8582 - mae: 411.3835 - val_loss: 498272.9062 - val_mae: 407.1086\n",
      "Epoch 21/500\n",
      "1407/1407 [==============================] - 1s 729us/step - loss: 489166.4135 - mae: 410.1002 - val_loss: 490287.2812 - val_mae: 403.8524\n",
      "Epoch 22/500\n",
      "1407/1407 [==============================] - 1s 731us/step - loss: 488888.5807 - mae: 409.2746 - val_loss: 491677.5312 - val_mae: 406.0904\n",
      "Epoch 23/500\n",
      "1407/1407 [==============================] - 1s 777us/step - loss: 486508.7588 - mae: 407.4431 - val_loss: 489108.9062 - val_mae: 403.9509\n",
      "Epoch 24/500\n",
      "1407/1407 [==============================] - 1s 794us/step - loss: 488579.9822 - mae: 408.7594 - val_loss: 488010.2812 - val_mae: 400.2860\n",
      "Epoch 25/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 465314.8938 - mae: 403.4340 - val_loss: 509741.2500 - val_mae: 422.0780\n",
      "Epoch 26/500\n",
      "1407/1407 [==============================] - 1s 731us/step - loss: 471860.1428 - mae: 405.9814 - val_loss: 497016.3438 - val_mae: 405.3809\n",
      "Epoch 27/500\n",
      "1407/1407 [==============================] - 1s 726us/step - loss: 480996.3780 - mae: 404.8040 - val_loss: 478631.5000 - val_mae: 402.2588\n",
      "Epoch 28/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 482629.5044 - mae: 405.5752 - val_loss: 483456.9375 - val_mae: 402.3268\n",
      "Epoch 29/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 478604.4109 - mae: 406.4047 - val_loss: 486824.2500 - val_mae: 405.1920\n",
      "Epoch 30/500\n",
      "1407/1407 [==============================] - 1s 733us/step - loss: 483126.9654 - mae: 404.5341 - val_loss: 481851.8438 - val_mae: 403.3027\n",
      "Epoch 31/500\n",
      "1407/1407 [==============================] - 1s 752us/step - loss: 471273.8550 - mae: 400.8598 - val_loss: 478924.5625 - val_mae: 402.1460\n",
      "Epoch 32/500\n",
      "1407/1407 [==============================] - 1s 748us/step - loss: 470601.5442 - mae: 403.1473 - val_loss: 474266.7188 - val_mae: 397.0388\n",
      "Epoch 33/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 460783.7628 - mae: 400.3825 - val_loss: 484371.0938 - val_mae: 413.7764\n",
      "Epoch 34/500\n",
      "1407/1407 [==============================] - 1s 744us/step - loss: 460194.2559 - mae: 402.0281 - val_loss: 472143.1250 - val_mae: 397.2111\n",
      "Epoch 35/500\n",
      "1407/1407 [==============================] - 1s 728us/step - loss: 452705.8318 - mae: 398.8019 - val_loss: 470368.3125 - val_mae: 397.9028\n",
      "Epoch 36/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 466949.0569 - mae: 400.1034 - val_loss: 467570.2188 - val_mae: 396.2811\n",
      "Epoch 37/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 455602.0249 - mae: 397.0503 - val_loss: 466904.5625 - val_mae: 395.3196\n",
      "Epoch 38/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 457565.6924 - mae: 396.5893 - val_loss: 470512.1875 - val_mae: 396.3520\n",
      "Epoch 39/500\n",
      "1407/1407 [==============================] - 1s 752us/step - loss: 465517.4006 - mae: 399.0305 - val_loss: 463008.5312 - val_mae: 394.0884\n",
      "Epoch 40/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 457489.1458 - mae: 396.7312 - val_loss: 467412.5625 - val_mae: 397.1891\n",
      "Epoch 41/500\n",
      "1407/1407 [==============================] - 1s 734us/step - loss: 461729.4116 - mae: 396.7925 - val_loss: 461879.5625 - val_mae: 395.0947\n",
      "Epoch 42/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 459734.4753 - mae: 396.7441 - val_loss: 461752.2188 - val_mae: 392.3093\n",
      "Epoch 43/500\n",
      "1407/1407 [==============================] - 1s 748us/step - loss: 456943.8326 - mae: 395.6892 - val_loss: 465138.0312 - val_mae: 397.6221\n",
      "Epoch 44/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 470688.5623 - mae: 397.4533 - val_loss: 467565.2500 - val_mae: 398.9892\n",
      "Epoch 45/500\n",
      "1407/1407 [==============================] - 1s 749us/step - loss: 468100.4476 - mae: 397.9433 - val_loss: 459288.5938 - val_mae: 393.1875\n",
      "Epoch 46/500\n",
      "1407/1407 [==============================] - 1s 728us/step - loss: 457147.5721 - mae: 394.6970 - val_loss: 459627.6562 - val_mae: 391.1716\n",
      "Epoch 47/500\n",
      "1407/1407 [==============================] - 1s 726us/step - loss: 454597.6060 - mae: 395.3992 - val_loss: 458382.5938 - val_mae: 392.1856\n",
      "Epoch 48/500\n",
      "1407/1407 [==============================] - 1s 728us/step - loss: 463109.4533 - mae: 394.6977 - val_loss: 458504.9062 - val_mae: 392.5325\n",
      "Epoch 49/500\n",
      "1407/1407 [==============================] - 1s 725us/step - loss: 445212.5041 - mae: 392.3126 - val_loss: 462148.8125 - val_mae: 395.7248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "1407/1407 [==============================] - 1s 699us/step - loss: 455766.8288 - mae: 393.3234 - val_loss: 457884.3125 - val_mae: 392.1299\n",
      "Epoch 51/500\n",
      "1407/1407 [==============================] - 1s 705us/step - loss: 458032.0260 - mae: 395.4644 - val_loss: 452815.3125 - val_mae: 390.3285\n",
      "Epoch 52/500\n",
      "1407/1407 [==============================] - 1s 704us/step - loss: 451864.5023 - mae: 393.1992 - val_loss: 455619.4688 - val_mae: 393.4771\n",
      "Epoch 53/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 454361.1155 - mae: 391.8430 - val_loss: 455298.3125 - val_mae: 392.0203\n",
      "Epoch 54/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 456278.2667 - mae: 396.3386 - val_loss: 454759.2812 - val_mae: 391.0663\n",
      "Epoch 55/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 448800.5014 - mae: 393.2427 - val_loss: 455767.5938 - val_mae: 391.3345\n",
      "Epoch 56/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 452990.3082 - mae: 392.7821 - val_loss: 455850.9062 - val_mae: 390.2458\n",
      "Epoch 57/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 457727.3176 - mae: 394.3487 - val_loss: 451924.8125 - val_mae: 391.4991\n",
      "Epoch 58/500\n",
      "1407/1407 [==============================] - 1s 714us/step - loss: 450413.0495 - mae: 392.2479 - val_loss: 450059.6875 - val_mae: 387.3206\n",
      "Epoch 59/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 462321.3010 - mae: 392.7654 - val_loss: 452364.3125 - val_mae: 389.5082\n",
      "Epoch 60/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 444154.2148 - mae: 389.1079 - val_loss: 451069.1875 - val_mae: 389.9290\n",
      "Epoch 61/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 456928.1518 - mae: 394.2060 - val_loss: 450932.1250 - val_mae: 389.7309\n",
      "Epoch 62/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 449338.5961 - mae: 391.3282 - val_loss: 448744.7812 - val_mae: 389.7360\n",
      "Epoch 63/500\n",
      "1407/1407 [==============================] - 1s 719us/step - loss: 461425.0784 - mae: 394.1912 - val_loss: 450700.8750 - val_mae: 387.3319\n",
      "Epoch 64/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 445287.9066 - mae: 388.2904 - val_loss: 452666.2812 - val_mae: 392.5535\n",
      "Epoch 65/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 455938.7852 - mae: 391.8382 - val_loss: 453164.6562 - val_mae: 388.8857\n",
      "Epoch 66/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 446083.5677 - mae: 390.0411 - val_loss: 447262.1562 - val_mae: 385.7869\n",
      "Epoch 67/500\n",
      "1407/1407 [==============================] - 1s 707us/step - loss: 454619.0325 - mae: 392.4846 - val_loss: 453858.8438 - val_mae: 391.5815\n",
      "Epoch 68/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 449691.7573 - mae: 390.1848 - val_loss: 447665.5312 - val_mae: 388.4459\n",
      "Epoch 69/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 438780.7112 - mae: 389.5183 - val_loss: 449671.4688 - val_mae: 386.8322\n",
      "Epoch 70/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 451777.1230 - mae: 391.0057 - val_loss: 448152.7500 - val_mae: 386.7204\n",
      "Epoch 71/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 445388.9148 - mae: 388.4161 - val_loss: 449964.1875 - val_mae: 386.9419\n",
      "Epoch 72/500\n",
      "1407/1407 [==============================] - 1s 730us/step - loss: 448482.3980 - mae: 389.0726 - val_loss: 447959.0000 - val_mae: 389.5355\n",
      "Epoch 73/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 439597.1077 - mae: 389.5273 - val_loss: 451440.8125 - val_mae: 388.1540\n",
      "Epoch 74/500\n",
      "1407/1407 [==============================] - 1s 771us/step - loss: 455690.6965 - mae: 389.4328 - val_loss: 451316.4375 - val_mae: 389.1664\n",
      "Epoch 75/500\n",
      "1407/1407 [==============================] - 1s 701us/step - loss: 446696.1093 - mae: 390.2003 - val_loss: 446755.2188 - val_mae: 388.7088\n",
      "Epoch 76/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 449847.0964 - mae: 387.9232 - val_loss: 454614.5312 - val_mae: 387.1931\n",
      "Epoch 77/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 438096.6815 - mae: 386.9012 - val_loss: 450817.8750 - val_mae: 390.2720\n",
      "Epoch 78/500\n",
      "1407/1407 [==============================] - 1s 746us/step - loss: 453930.7237 - mae: 392.2627 - val_loss: 446906.6250 - val_mae: 385.9642\n",
      "Epoch 79/500\n",
      "1407/1407 [==============================] - 1s 776us/step - loss: 447139.3906 - mae: 389.7871 - val_loss: 448051.0000 - val_mae: 386.2685\n",
      "Epoch 80/500\n",
      "1407/1407 [==============================] - 1s 728us/step - loss: 447698.0590 - mae: 389.6268 - val_loss: 444689.2188 - val_mae: 384.3332\n",
      "Epoch 81/500\n",
      "1407/1407 [==============================] - 1s 734us/step - loss: 444783.8506 - mae: 388.9137 - val_loss: 446713.4375 - val_mae: 384.9450\n",
      "Epoch 82/500\n",
      "1407/1407 [==============================] - 1s 703us/step - loss: 445477.3369 - mae: 390.1634 - val_loss: 450531.3125 - val_mae: 387.5962\n",
      "Epoch 83/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 450630.9439 - mae: 389.7925 - val_loss: 445861.0625 - val_mae: 388.0677\n",
      "Epoch 84/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 453458.3104 - mae: 390.4993 - val_loss: 447386.4375 - val_mae: 390.2033\n",
      "Epoch 85/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 457607.6096 - mae: 389.7459 - val_loss: 445126.7812 - val_mae: 385.6288\n",
      "Epoch 86/500\n",
      "1407/1407 [==============================] - 1s 733us/step - loss: 450390.2348 - mae: 387.4793 - val_loss: 448734.6562 - val_mae: 393.5291\n",
      "Epoch 87/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 447640.1643 - mae: 391.1623 - val_loss: 446168.1562 - val_mae: 389.7515\n",
      "Epoch 88/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 435305.8706 - mae: 387.5789 - val_loss: 443312.9062 - val_mae: 384.9094\n",
      "Epoch 89/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 438408.3222 - mae: 386.4036 - val_loss: 444156.6562 - val_mae: 382.9637\n",
      "Epoch 90/500\n",
      "1407/1407 [==============================] - 1s 715us/step - loss: 438754.0795 - mae: 387.0933 - val_loss: 443927.4062 - val_mae: 386.5898\n",
      "Epoch 91/500\n",
      "1407/1407 [==============================] - 1s 725us/step - loss: 443372.3976 - mae: 387.6133 - val_loss: 444886.5312 - val_mae: 387.8209\n",
      "Epoch 92/500\n",
      "1407/1407 [==============================] - 1s 734us/step - loss: 443960.9829 - mae: 388.4328 - val_loss: 444590.7500 - val_mae: 385.5283\n",
      "Epoch 93/500\n",
      "1407/1407 [==============================] - 1s 726us/step - loss: 445135.3936 - mae: 386.9459 - val_loss: 443867.1875 - val_mae: 385.2313\n",
      "Epoch 94/500\n",
      "1407/1407 [==============================] - 1s 719us/step - loss: 444662.1967 - mae: 388.8269 - val_loss: 442278.8438 - val_mae: 385.9124\n",
      "Epoch 95/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 445985.9320 - mae: 388.9710 - val_loss: 446562.0000 - val_mae: 384.8401\n",
      "Epoch 96/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 444960.5394 - mae: 387.6952 - val_loss: 445504.3438 - val_mae: 386.6546\n",
      "Epoch 97/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 437607.5505 - mae: 385.3708 - val_loss: 443822.8125 - val_mae: 387.1764\n",
      "Epoch 98/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 446703.3228 - mae: 386.6413 - val_loss: 442607.5000 - val_mae: 385.3841\n",
      "Epoch 99/500\n",
      "1407/1407 [==============================] - 1s 734us/step - loss: 444419.1840 - mae: 387.1623 - val_loss: 442532.3125 - val_mae: 386.2987\n",
      "Epoch 100/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 452748.4382 - mae: 389.8065 - val_loss: 442517.6562 - val_mae: 386.4979\n",
      "Epoch 101/500\n",
      "1407/1407 [==============================] - 1s 719us/step - loss: 439093.0253 - mae: 386.2714 - val_loss: 443001.8125 - val_mae: 384.2183\n",
      "Epoch 102/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 437289.1638 - mae: 385.4890 - val_loss: 443424.7812 - val_mae: 384.6922\n",
      "Epoch 103/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 439875.5783 - mae: 386.9111 - val_loss: 442272.3750 - val_mae: 384.5359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 437500.6298 - mae: 387.9059 - val_loss: 441382.2188 - val_mae: 383.4803\n",
      "Epoch 105/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 428503.8282 - mae: 384.5926 - val_loss: 444199.6875 - val_mae: 389.6179\n",
      "Epoch 106/500\n",
      "1407/1407 [==============================] - 1s 705us/step - loss: 442980.4238 - mae: 388.7562 - val_loss: 442157.4688 - val_mae: 386.2599\n",
      "Epoch 107/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 447730.5226 - mae: 388.5286 - val_loss: 442982.6250 - val_mae: 391.8236\n",
      "Epoch 108/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 444642.6256 - mae: 386.7755 - val_loss: 443896.1250 - val_mae: 384.9022\n",
      "Epoch 109/500\n",
      "1407/1407 [==============================] - 1s 715us/step - loss: 442296.7228 - mae: 386.5107 - val_loss: 441938.7812 - val_mae: 383.6938\n",
      "Epoch 110/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 436614.3721 - mae: 386.3769 - val_loss: 440819.4375 - val_mae: 385.5130\n",
      "Epoch 111/500\n",
      "1407/1407 [==============================] - 1s 707us/step - loss: 434129.6014 - mae: 385.2095 - val_loss: 443317.7188 - val_mae: 385.8571\n",
      "Epoch 112/500\n",
      "1407/1407 [==============================] - 1s 715us/step - loss: 439787.4607 - mae: 388.5714 - val_loss: 439889.2500 - val_mae: 384.0107\n",
      "Epoch 113/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 435754.9353 - mae: 386.6091 - val_loss: 438807.8750 - val_mae: 385.6520\n",
      "Epoch 114/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 457891.9000 - mae: 390.3666 - val_loss: 439082.7812 - val_mae: 383.2372\n",
      "Epoch 115/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 438604.4583 - mae: 385.9889 - val_loss: 440839.6875 - val_mae: 383.4077\n",
      "Epoch 116/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 423337.6873 - mae: 383.3899 - val_loss: 439753.4062 - val_mae: 384.8649\n",
      "Epoch 117/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 444338.7874 - mae: 386.9934 - val_loss: 438854.4688 - val_mae: 384.2366\n",
      "Epoch 118/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 437162.0696 - mae: 385.9843 - val_loss: 439610.6875 - val_mae: 386.6484\n",
      "Epoch 119/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 445301.0633 - mae: 387.1412 - val_loss: 441079.4062 - val_mae: 384.0892\n",
      "Epoch 120/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 439620.9588 - mae: 386.5358 - val_loss: 439336.0312 - val_mae: 384.7458\n",
      "Epoch 121/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 443212.2293 - mae: 384.5826 - val_loss: 440561.4688 - val_mae: 384.7467\n",
      "Epoch 122/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 435069.8592 - mae: 385.9449 - val_loss: 439931.5312 - val_mae: 385.8333\n",
      "Epoch 123/500\n",
      "1407/1407 [==============================] - 1s 738us/step - loss: 437561.0837 - mae: 386.6443 - val_loss: 438743.5938 - val_mae: 383.5909\n",
      "Epoch 124/500\n",
      "1407/1407 [==============================] - 1s 742us/step - loss: 433850.4086 - mae: 384.1998 - val_loss: 438612.3438 - val_mae: 384.1364\n",
      "Epoch 125/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 453300.9911 - mae: 388.4996 - val_loss: 438536.2500 - val_mae: 383.3872\n",
      "Epoch 126/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 439821.7818 - mae: 384.9520 - val_loss: 439006.1562 - val_mae: 383.8841\n",
      "Epoch 127/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 441993.9938 - mae: 386.7583 - val_loss: 438721.0938 - val_mae: 382.6887\n",
      "Epoch 128/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 435381.4546 - mae: 386.9138 - val_loss: 438982.5625 - val_mae: 385.5806\n",
      "Epoch 129/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 447148.1088 - mae: 387.9303 - val_loss: 438967.5938 - val_mae: 383.1833\n",
      "Epoch 130/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 438770.9952 - mae: 386.9667 - val_loss: 438760.8750 - val_mae: 382.8839\n",
      "Epoch 131/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 444237.9878 - mae: 387.7528 - val_loss: 437774.2812 - val_mae: 384.3712\n",
      "Epoch 132/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 446841.8637 - mae: 386.9965 - val_loss: 440622.4062 - val_mae: 385.9434\n",
      "Epoch 133/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 433170.5524 - mae: 385.6340 - val_loss: 438862.4688 - val_mae: 384.3390\n",
      "Epoch 134/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 439470.1347 - mae: 386.4516 - val_loss: 439935.1250 - val_mae: 383.1964\n",
      "Epoch 135/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 442092.7981 - mae: 385.6256 - val_loss: 439724.2188 - val_mae: 382.2345\n",
      "Epoch 136/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 446987.0721 - mae: 387.0527 - val_loss: 439038.1875 - val_mae: 382.8099\n",
      "Epoch 137/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 429625.5657 - mae: 384.1938 - val_loss: 437555.9688 - val_mae: 384.2805\n",
      "Epoch 138/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 435643.3476 - mae: 384.4990 - val_loss: 436516.6875 - val_mae: 382.9902\n",
      "Epoch 139/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 440417.8956 - mae: 386.6061 - val_loss: 437202.4062 - val_mae: 384.6349\n",
      "Epoch 140/500\n",
      "1407/1407 [==============================] - 1s 731us/step - loss: 435688.0621 - mae: 383.9791 - val_loss: 436514.7500 - val_mae: 383.4201\n",
      "Epoch 141/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 434275.9074 - mae: 383.7258 - val_loss: 437249.5000 - val_mae: 383.0254\n",
      "Epoch 142/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 440486.5021 - mae: 387.4503 - val_loss: 438152.1250 - val_mae: 384.2235\n",
      "Epoch 143/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 448297.9534 - mae: 389.4687 - val_loss: 436982.4062 - val_mae: 384.4898\n",
      "Epoch 144/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 437000.3663 - mae: 385.4585 - val_loss: 436002.6875 - val_mae: 382.8129\n",
      "Epoch 145/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 446378.0385 - mae: 387.8396 - val_loss: 436187.5000 - val_mae: 383.1912\n",
      "Epoch 146/500\n",
      "1407/1407 [==============================] - 1s 724us/step - loss: 439392.4377 - mae: 385.9866 - val_loss: 437628.3750 - val_mae: 383.0519\n",
      "Epoch 147/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 443383.6966 - mae: 385.0909 - val_loss: 437629.0000 - val_mae: 382.3258\n",
      "Epoch 148/500\n",
      "1407/1407 [==============================] - 1s 714us/step - loss: 432815.4806 - mae: 384.7595 - val_loss: 435975.7188 - val_mae: 383.4269\n",
      "Epoch 149/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 431449.6142 - mae: 384.0075 - val_loss: 436652.4375 - val_mae: 383.5919\n",
      "Epoch 150/500\n",
      "1407/1407 [==============================] - 1s 795us/step - loss: 433797.9021 - mae: 383.9062 - val_loss: 435889.7500 - val_mae: 383.1905\n",
      "Epoch 151/500\n",
      "1407/1407 [==============================] - 1s 743us/step - loss: 431522.1370 - mae: 385.4532 - val_loss: 437025.2812 - val_mae: 382.8573\n",
      "Epoch 152/500\n",
      "1407/1407 [==============================] - 1s 739us/step - loss: 431731.9883 - mae: 384.2936 - val_loss: 437529.2812 - val_mae: 381.8550\n",
      "Epoch 153/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 447339.2433 - mae: 385.5032 - val_loss: 436903.4688 - val_mae: 382.3285\n",
      "Epoch 154/500\n",
      "1407/1407 [==============================] - 1s 754us/step - loss: 433932.6846 - mae: 383.7550 - val_loss: 436113.9688 - val_mae: 383.5058\n",
      "Epoch 155/500\n",
      "1407/1407 [==============================] - 1s 772us/step - loss: 435129.9709 - mae: 384.4611 - val_loss: 436773.8438 - val_mae: 383.2446\n",
      "Epoch 156/500\n",
      "1407/1407 [==============================] - 1s 763us/step - loss: 444225.1667 - mae: 386.9327 - val_loss: 436677.8750 - val_mae: 383.6388\n",
      "Epoch 157/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 440155.9510 - mae: 386.6742 - val_loss: 437047.1250 - val_mae: 381.5567\n",
      "Epoch 158/500\n",
      "1407/1407 [==============================] - 1s 704us/step - loss: 434922.7300 - mae: 383.0495 - val_loss: 439856.0625 - val_mae: 389.4583\n",
      "Epoch 159/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 440717.1614 - mae: 386.5709 - val_loss: 436622.2812 - val_mae: 384.2095\n",
      "Epoch 160/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 425014.7225 - mae: 383.2763 - val_loss: 435148.6562 - val_mae: 382.1888\n",
      "Epoch 161/500\n",
      "1407/1407 [==============================] - 1s 707us/step - loss: 436299.6019 - mae: 384.3243 - val_loss: 437096.9375 - val_mae: 383.3022\n",
      "Epoch 162/500\n",
      "1407/1407 [==============================] - 1s 706us/step - loss: 434699.6898 - mae: 385.3854 - val_loss: 437338.6250 - val_mae: 384.2740\n",
      "Epoch 163/500\n",
      "1407/1407 [==============================] - 1s 704us/step - loss: 426843.2242 - mae: 381.9991 - val_loss: 436293.3125 - val_mae: 381.9378\n",
      "Epoch 164/500\n",
      "1407/1407 [==============================] - 1s 724us/step - loss: 441712.4524 - mae: 385.7270 - val_loss: 437038.0625 - val_mae: 383.0828\n",
      "Epoch 165/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 440701.6577 - mae: 385.3234 - val_loss: 435998.8125 - val_mae: 382.6034\n",
      "Epoch 166/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 425790.5243 - mae: 382.3260 - val_loss: 436906.6250 - val_mae: 383.9218\n",
      "Epoch 167/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 430265.0264 - mae: 382.7153 - val_loss: 437195.2500 - val_mae: 382.2354\n",
      "Epoch 168/500\n",
      "1407/1407 [==============================] - 1s 721us/step - loss: 431844.5806 - mae: 384.8926 - val_loss: 437101.0000 - val_mae: 382.8249\n",
      "Epoch 169/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 433521.3390 - mae: 382.3938 - val_loss: 435244.6562 - val_mae: 383.1395\n",
      "Epoch 170/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 445797.4596 - mae: 385.5350 - val_loss: 436527.6875 - val_mae: 382.1619\n",
      "Epoch 171/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 427747.8363 - mae: 382.2197 - val_loss: 435302.8438 - val_mae: 381.5821\n",
      "Epoch 172/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 439688.0454 - mae: 382.9882 - val_loss: 435088.6875 - val_mae: 382.1320\n",
      "Epoch 173/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 436095.0704 - mae: 382.3558 - val_loss: 437308.1250 - val_mae: 385.1311\n",
      "Epoch 174/500\n",
      "1407/1407 [==============================] - 1s 714us/step - loss: 432063.8469 - mae: 383.8713 - val_loss: 436419.0000 - val_mae: 382.0307\n",
      "Epoch 175/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 436979.5714 - mae: 383.9774 - val_loss: 434662.5938 - val_mae: 381.7913\n",
      "Epoch 176/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 439612.7986 - mae: 384.4525 - val_loss: 435551.9375 - val_mae: 381.7763\n",
      "Epoch 177/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 432211.3568 - mae: 383.8497 - val_loss: 436742.2812 - val_mae: 382.9767\n",
      "Epoch 178/500\n",
      "1407/1407 [==============================] - 1s 708us/step - loss: 435864.7719 - mae: 383.9718 - val_loss: 434496.8750 - val_mae: 382.4741\n",
      "Epoch 179/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 426279.5076 - mae: 383.2901 - val_loss: 434235.4062 - val_mae: 382.0992\n",
      "Epoch 180/500\n",
      "1407/1407 [==============================] - 1s 732us/step - loss: 438310.9650 - mae: 383.5034 - val_loss: 436507.5000 - val_mae: 381.3626\n",
      "Epoch 181/500\n",
      "1407/1407 [==============================] - 1s 710us/step - loss: 428741.9389 - mae: 381.6483 - val_loss: 435217.3125 - val_mae: 382.9794\n",
      "Epoch 182/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 434749.6077 - mae: 383.0800 - val_loss: 435173.0625 - val_mae: 381.3512\n",
      "Epoch 183/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 430396.4975 - mae: 384.0463 - val_loss: 435016.0000 - val_mae: 382.5575\n",
      "Epoch 184/500\n",
      "1407/1407 [==============================] - 1s 715us/step - loss: 437205.8743 - mae: 384.0545 - val_loss: 435220.9688 - val_mae: 382.7451\n",
      "Epoch 185/500\n",
      "1407/1407 [==============================] - 1s 724us/step - loss: 429554.7032 - mae: 383.1098 - val_loss: 434586.3438 - val_mae: 382.0212\n",
      "Epoch 186/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 428637.5482 - mae: 382.9603 - val_loss: 436842.3750 - val_mae: 383.1046\n",
      "Epoch 187/500\n",
      "1407/1407 [==============================] - 1s 714us/step - loss: 444138.4943 - mae: 383.4626 - val_loss: 434723.9688 - val_mae: 382.5061\n",
      "Epoch 188/500\n",
      "1407/1407 [==============================] - 1s 721us/step - loss: 425550.2974 - mae: 382.8658 - val_loss: 434961.7812 - val_mae: 382.0732\n",
      "Epoch 189/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 433897.3232 - mae: 382.1251 - val_loss: 436764.5938 - val_mae: 381.0679\n",
      "Epoch 190/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 426384.9778 - mae: 381.2203 - val_loss: 435584.9375 - val_mae: 382.5516\n",
      "Epoch 191/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 438952.3013 - mae: 386.2667 - val_loss: 434428.3750 - val_mae: 382.5568\n",
      "Epoch 192/500\n",
      "1407/1407 [==============================] - 1s 764us/step - loss: 430067.1969 - mae: 382.3661 - val_loss: 433825.7188 - val_mae: 382.1675\n",
      "Epoch 193/500\n",
      "1407/1407 [==============================] - 1s 763us/step - loss: 435699.1172 - mae: 384.3096 - val_loss: 434754.9375 - val_mae: 381.8684\n",
      "Epoch 194/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 428784.3849 - mae: 380.8247 - val_loss: 435723.0000 - val_mae: 381.5921\n",
      "Epoch 195/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 429816.0606 - mae: 383.4915 - val_loss: 434140.5938 - val_mae: 382.0417\n",
      "Epoch 196/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 436603.2924 - mae: 384.7729 - val_loss: 434940.0000 - val_mae: 382.8667\n",
      "Epoch 197/500\n",
      "1407/1407 [==============================] - 1s 719us/step - loss: 424086.4958 - mae: 380.0602 - val_loss: 435040.0000 - val_mae: 382.9205\n",
      "Epoch 198/500\n",
      "1407/1407 [==============================] - 1s 738us/step - loss: 433976.8987 - mae: 381.5853 - val_loss: 434473.4375 - val_mae: 381.6360\n",
      "Epoch 199/500\n",
      "1407/1407 [==============================] - 1s 743us/step - loss: 433496.9103 - mae: 383.3442 - val_loss: 435148.5938 - val_mae: 381.0625\n",
      "Epoch 200/500\n",
      "1407/1407 [==============================] - 1s 736us/step - loss: 433266.7059 - mae: 383.7857 - val_loss: 435471.5938 - val_mae: 381.8230\n",
      "Epoch 201/500\n",
      "1407/1407 [==============================] - 1s 725us/step - loss: 424567.5746 - mae: 380.4740 - val_loss: 434329.0625 - val_mae: 382.1711\n",
      "Epoch 202/500\n",
      "1407/1407 [==============================] - 1s 719us/step - loss: 437115.8378 - mae: 384.7973 - val_loss: 435530.4688 - val_mae: 382.9082\n",
      "Epoch 203/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 428702.9817 - mae: 382.7352 - val_loss: 434139.2188 - val_mae: 380.9612\n",
      "Epoch 204/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 431776.3420 - mae: 380.5530 - val_loss: 434446.8438 - val_mae: 381.5057\n",
      "Epoch 205/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 437308.4996 - mae: 383.7084 - val_loss: 436584.2500 - val_mae: 381.9161\n",
      "Epoch 206/500\n",
      "1407/1407 [==============================] - 1s 715us/step - loss: 430370.9891 - mae: 383.2695 - val_loss: 434549.4375 - val_mae: 382.5716\n",
      "Epoch 207/500\n",
      "1407/1407 [==============================] - 1s 706us/step - loss: 423971.9338 - mae: 381.4949 - val_loss: 434581.6250 - val_mae: 381.3193\n",
      "Epoch 208/500\n",
      "1407/1407 [==============================] - 1s 716us/step - loss: 433977.5899 - mae: 382.8230 - val_loss: 435290.7500 - val_mae: 382.1103\n",
      "Epoch 209/500\n",
      "1407/1407 [==============================] - 1s 731us/step - loss: 427488.5231 - mae: 384.0032 - val_loss: 433686.6562 - val_mae: 381.8079\n",
      "Epoch 210/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 1s 714us/step - loss: 441728.7006 - mae: 384.6361 - val_loss: 433978.5312 - val_mae: 381.1721\n",
      "Epoch 211/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 434303.6630 - mae: 383.6002 - val_loss: 434353.9375 - val_mae: 382.1355\n",
      "Epoch 212/500\n",
      "1407/1407 [==============================] - 1s 732us/step - loss: 428739.4144 - mae: 382.7785 - val_loss: 433905.5312 - val_mae: 381.5551\n",
      "Epoch 213/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 422939.3770 - mae: 381.5072 - val_loss: 434301.9688 - val_mae: 382.2940\n",
      "Epoch 214/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 426519.5975 - mae: 381.2544 - val_loss: 433980.8438 - val_mae: 381.1097\n",
      "Epoch 215/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 434441.8305 - mae: 383.4188 - val_loss: 434008.1562 - val_mae: 380.7713\n",
      "Epoch 216/500\n",
      "1407/1407 [==============================] - 1s 810us/step - loss: 432213.1477 - mae: 384.7856 - val_loss: 433954.9062 - val_mae: 382.2240\n",
      "Epoch 217/500\n",
      "1407/1407 [==============================] - 1s 879us/step - loss: 427720.8179 - mae: 382.1501 - val_loss: 433561.0000 - val_mae: 381.4993\n",
      "Epoch 218/500\n",
      "1407/1407 [==============================] - 1s 862us/step - loss: 444600.0386 - mae: 384.7327 - val_loss: 434437.0312 - val_mae: 381.8283\n",
      "Epoch 219/500\n",
      "1407/1407 [==============================] - 1s 817us/step - loss: 434153.6052 - mae: 382.8986 - val_loss: 434823.1562 - val_mae: 382.4188\n",
      "Epoch 220/500\n",
      "1407/1407 [==============================] - 1s 755us/step - loss: 431597.3909 - mae: 383.2030 - val_loss: 433864.1562 - val_mae: 381.8709\n",
      "Epoch 221/500\n",
      "1407/1407 [==============================] - 1s 739us/step - loss: 426748.1640 - mae: 380.8282 - val_loss: 433462.8125 - val_mae: 382.5764\n",
      "Epoch 222/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 432925.6881 - mae: 383.0287 - val_loss: 434170.5000 - val_mae: 382.2884\n",
      "Epoch 223/500\n",
      "1407/1407 [==============================] - 1s 726us/step - loss: 442956.9585 - mae: 385.5923 - val_loss: 433694.0625 - val_mae: 381.8235\n",
      "Epoch 224/500\n",
      "1407/1407 [==============================] - 1s 728us/step - loss: 428242.6033 - mae: 382.2417 - val_loss: 433898.0938 - val_mae: 380.7940\n",
      "Epoch 225/500\n",
      "1407/1407 [==============================] - 1s 742us/step - loss: 426493.2390 - mae: 379.0897 - val_loss: 433632.8125 - val_mae: 381.4296\n",
      "Epoch 226/500\n",
      "1407/1407 [==============================] - 1s 787us/step - loss: 440922.0821 - mae: 383.5501 - val_loss: 434731.1250 - val_mae: 382.0233\n",
      "Epoch 227/500\n",
      "1407/1407 [==============================] - 1s 760us/step - loss: 436396.5678 - mae: 383.4406 - val_loss: 433461.2500 - val_mae: 381.3222\n",
      "Epoch 228/500\n",
      "1407/1407 [==============================] - 1s 768us/step - loss: 435698.8437 - mae: 383.5121 - val_loss: 433813.5938 - val_mae: 382.2493\n",
      "Epoch 229/500\n",
      "1407/1407 [==============================] - 1s 762us/step - loss: 429450.8726 - mae: 382.7170 - val_loss: 433943.6562 - val_mae: 381.5772\n",
      "Epoch 230/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 439626.1111 - mae: 384.6723 - val_loss: 434063.9375 - val_mae: 382.2503\n",
      "Epoch 231/500\n",
      "1407/1407 [==============================] - 1s 731us/step - loss: 437067.4834 - mae: 382.5518 - val_loss: 433894.5625 - val_mae: 381.4069\n",
      "Epoch 232/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 436763.3730 - mae: 383.7456 - val_loss: 433508.5312 - val_mae: 381.2300\n",
      "Epoch 233/500\n",
      "1407/1407 [==============================] - 1s 725us/step - loss: 428408.3732 - mae: 380.7526 - val_loss: 433947.6250 - val_mae: 382.0181\n",
      "Epoch 234/500\n",
      "1407/1407 [==============================] - 1s 753us/step - loss: 433307.9996 - mae: 382.2164 - val_loss: 433900.2812 - val_mae: 381.9514\n",
      "Epoch 235/500\n",
      "1407/1407 [==============================] - 1s 748us/step - loss: 439672.1888 - mae: 383.2839 - val_loss: 433852.8125 - val_mae: 381.1606\n",
      "Epoch 236/500\n",
      "1407/1407 [==============================] - 1s 738us/step - loss: 432272.9156 - mae: 383.4322 - val_loss: 433391.5000 - val_mae: 381.0997\n",
      "Epoch 237/500\n",
      "1407/1407 [==============================] - 1s 737us/step - loss: 426529.1635 - mae: 381.0701 - val_loss: 433277.7812 - val_mae: 381.9563\n",
      "Epoch 238/500\n",
      "1407/1407 [==============================] - 1s 757us/step - loss: 420863.0155 - mae: 382.0526 - val_loss: 434279.1875 - val_mae: 381.8949\n",
      "Epoch 239/500\n",
      "1407/1407 [==============================] - 1s 772us/step - loss: 435676.6231 - mae: 383.9813 - val_loss: 433500.1250 - val_mae: 380.6915\n",
      "Epoch 240/500\n",
      "1407/1407 [==============================] - 1s 756us/step - loss: 430776.1963 - mae: 382.6980 - val_loss: 434418.9062 - val_mae: 382.1822\n",
      "Epoch 241/500\n",
      "1407/1407 [==============================] - 1s 742us/step - loss: 436756.6022 - mae: 383.8095 - val_loss: 433734.3125 - val_mae: 380.7260\n",
      "Epoch 242/500\n",
      "1407/1407 [==============================] - 1s 744us/step - loss: 433762.4449 - mae: 383.2243 - val_loss: 433692.1875 - val_mae: 381.7731\n",
      "Epoch 243/500\n",
      "1407/1407 [==============================] - 1s 756us/step - loss: 444205.2961 - mae: 385.6512 - val_loss: 434098.1875 - val_mae: 380.9256\n",
      "Epoch 244/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 431874.1517 - mae: 382.0331 - val_loss: 433774.0312 - val_mae: 381.9115\n",
      "Epoch 245/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 441513.6597 - mae: 385.1683 - val_loss: 433463.5938 - val_mae: 380.5689\n",
      "Epoch 246/500\n",
      "1407/1407 [==============================] - 1s 751us/step - loss: 434053.0097 - mae: 383.4846 - val_loss: 433644.4062 - val_mae: 380.8299\n",
      "Epoch 247/500\n",
      "1407/1407 [==============================] - 1s 804us/step - loss: 428935.0392 - mae: 381.7013 - val_loss: 433511.2812 - val_mae: 381.0591\n",
      "Epoch 248/500\n",
      "1407/1407 [==============================] - 1s 780us/step - loss: 426239.8302 - mae: 379.9273 - val_loss: 433530.5625 - val_mae: 380.6845\n",
      "Epoch 249/500\n",
      "1407/1407 [==============================] - 1s 907us/step - loss: 434719.3234 - mae: 383.9305 - val_loss: 434020.4375 - val_mae: 381.8027\n",
      "Epoch 250/500\n",
      "1407/1407 [==============================] - 1s 869us/step - loss: 431936.5941 - mae: 382.9075 - val_loss: 433933.8438 - val_mae: 380.9836\n",
      "Epoch 251/500\n",
      "1407/1407 [==============================] - 1s 861us/step - loss: 426904.1407 - mae: 383.1650 - val_loss: 433734.3750 - val_mae: 381.9883\n",
      "Epoch 252/500\n",
      "1407/1407 [==============================] - 1s 888us/step - loss: 442071.1449 - mae: 382.6000 - val_loss: 433850.2812 - val_mae: 381.4347\n",
      "Epoch 253/500\n",
      "1407/1407 [==============================] - 1s 822us/step - loss: 433476.9871 - mae: 383.4087 - val_loss: 433414.7188 - val_mae: 381.8785\n",
      "Epoch 254/500\n",
      "1407/1407 [==============================] - 1s 873us/step - loss: 426061.9481 - mae: 381.5854 - val_loss: 433793.6875 - val_mae: 380.9654\n",
      "Epoch 255/500\n",
      "1407/1407 [==============================] - 1s 834us/step - loss: 421991.8296 - mae: 379.0975 - val_loss: 433457.0000 - val_mae: 381.6312\n",
      "Epoch 256/500\n",
      "1407/1407 [==============================] - 1s 855us/step - loss: 430954.5701 - mae: 381.4417 - val_loss: 433756.8125 - val_mae: 381.2856\n",
      "Epoch 257/500\n",
      "1407/1407 [==============================] - 1s 803us/step - loss: 425448.3214 - mae: 381.1532 - val_loss: 433767.9688 - val_mae: 381.8358\n",
      "Epoch 258/500\n",
      "1407/1407 [==============================] - 1s 811us/step - loss: 427720.3138 - mae: 379.8385 - val_loss: 433294.8438 - val_mae: 381.6128\n",
      "Epoch 259/500\n",
      "1407/1407 [==============================] - 1s 788us/step - loss: 435523.9284 - mae: 381.7624 - val_loss: 433338.1562 - val_mae: 381.1205\n",
      "Epoch 260/500\n",
      "1407/1407 [==============================] - 1s 920us/step - loss: 425276.7930 - mae: 382.2918 - val_loss: 433470.5938 - val_mae: 381.3991\n",
      "Epoch 261/500\n",
      "1407/1407 [==============================] - 1s 803us/step - loss: 434007.5842 - mae: 383.9851 - val_loss: 433480.9375 - val_mae: 380.7838\n",
      "Epoch 262/500\n",
      "1407/1407 [==============================] - 1s 825us/step - loss: 430769.0396 - mae: 382.1869 - val_loss: 433092.9688 - val_mae: 381.8073\n",
      "Epoch 263/500\n",
      "1407/1407 [==============================] - 1s 777us/step - loss: 431107.4771 - mae: 381.6395 - val_loss: 433327.9062 - val_mae: 381.3330\n",
      "Epoch 264/500\n",
      "1407/1407 [==============================] - 1s 760us/step - loss: 432974.4306 - mae: 382.7555 - val_loss: 433083.1875 - val_mae: 381.0987\n",
      "Epoch 265/500\n",
      "1407/1407 [==============================] - 1s 730us/step - loss: 432421.2464 - mae: 381.1374 - val_loss: 433153.5938 - val_mae: 380.9793\n",
      "Epoch 266/500\n",
      "1407/1407 [==============================] - 1s 765us/step - loss: 433455.4480 - mae: 383.0277 - val_loss: 433875.3125 - val_mae: 381.7468\n",
      "Epoch 267/500\n",
      "1407/1407 [==============================] - 1s 755us/step - loss: 436603.5802 - mae: 383.1224 - val_loss: 433457.2188 - val_mae: 381.4323\n",
      "Epoch 268/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 436260.7895 - mae: 383.9989 - val_loss: 433533.5625 - val_mae: 380.9923\n",
      "Epoch 269/500\n",
      "1407/1407 [==============================] - 1s 756us/step - loss: 432937.0799 - mae: 381.5199 - val_loss: 433096.1875 - val_mae: 380.7351\n",
      "Epoch 270/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 430895.0293 - mae: 381.4849 - val_loss: 433444.0312 - val_mae: 381.4613\n",
      "Epoch 271/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 430029.7460 - mae: 381.3729 - val_loss: 432956.1250 - val_mae: 381.2873\n",
      "Epoch 272/500\n",
      "1407/1407 [==============================] - 1s 743us/step - loss: 433004.0866 - mae: 382.5689 - val_loss: 433168.9688 - val_mae: 381.5644\n",
      "Epoch 273/500\n",
      "1407/1407 [==============================] - 1s 774us/step - loss: 431869.7505 - mae: 382.8221 - val_loss: 433825.6875 - val_mae: 382.0750\n",
      "Epoch 274/500\n",
      "1407/1407 [==============================] - 1s 726us/step - loss: 428669.3792 - mae: 380.2614 - val_loss: 433652.2188 - val_mae: 382.1877\n",
      "Epoch 275/500\n",
      "1407/1407 [==============================] - 1s 757us/step - loss: 432536.0265 - mae: 383.1789 - val_loss: 433572.4375 - val_mae: 381.2135\n",
      "Epoch 276/500\n",
      "1407/1407 [==============================] - 1s 754us/step - loss: 433618.3143 - mae: 382.2489 - val_loss: 433617.1250 - val_mae: 381.6058\n",
      "Epoch 277/500\n",
      "1407/1407 [==============================] - 1s 738us/step - loss: 441739.3073 - mae: 384.1726 - val_loss: 432992.1875 - val_mae: 381.2885\n",
      "Epoch 278/500\n",
      "1407/1407 [==============================] - 1s 781us/step - loss: 431301.6493 - mae: 382.7455 - val_loss: 433161.6875 - val_mae: 380.9561\n",
      "Epoch 279/500\n",
      "1407/1407 [==============================] - 1s 831us/step - loss: 427920.4661 - mae: 380.9194 - val_loss: 433377.5312 - val_mae: 381.2472\n",
      "Epoch 280/500\n",
      "1407/1407 [==============================] - 1s 862us/step - loss: 433161.3686 - mae: 383.3677 - val_loss: 433215.1875 - val_mae: 381.1828\n",
      "Epoch 281/500\n",
      "1407/1407 [==============================] - 1s 822us/step - loss: 426761.2014 - mae: 381.4138 - val_loss: 433068.1562 - val_mae: 381.2469\n",
      "Epoch 282/500\n",
      "1407/1407 [==============================] - 1s 834us/step - loss: 434068.4601 - mae: 382.4783 - val_loss: 433354.1875 - val_mae: 381.5751\n",
      "Epoch 283/500\n",
      "1407/1407 [==============================] - 1s 763us/step - loss: 426865.3153 - mae: 382.0114 - val_loss: 432891.4375 - val_mae: 381.3113\n",
      "Epoch 284/500\n",
      "1407/1407 [==============================] - 1s 754us/step - loss: 444320.6610 - mae: 384.9628 - val_loss: 433095.9062 - val_mae: 380.9013\n",
      "Epoch 285/500\n",
      "1407/1407 [==============================] - 1s 752us/step - loss: 428329.0297 - mae: 382.3902 - val_loss: 433303.8438 - val_mae: 381.3675\n",
      "Epoch 286/500\n",
      "1407/1407 [==============================] - 1s 741us/step - loss: 436747.5409 - mae: 383.2863 - val_loss: 433009.1875 - val_mae: 381.0348\n",
      "Epoch 287/500\n",
      "1407/1407 [==============================] - 1s 724us/step - loss: 428980.5415 - mae: 380.6170 - val_loss: 432889.8125 - val_mae: 380.6129\n",
      "Epoch 288/500\n",
      "1407/1407 [==============================] - 1s 797us/step - loss: 430729.7773 - mae: 381.7177 - val_loss: 433235.1875 - val_mae: 380.9656\n",
      "Epoch 289/500\n",
      "1407/1407 [==============================] - 1s 801us/step - loss: 437148.2163 - mae: 382.0008 - val_loss: 433228.0625 - val_mae: 381.5484\n",
      "Epoch 290/500\n",
      "1407/1407 [==============================] - 1s 763us/step - loss: 433784.8427 - mae: 382.1474 - val_loss: 433188.8438 - val_mae: 381.1691\n",
      "Epoch 291/500\n",
      "1407/1407 [==============================] - 1s 778us/step - loss: 431967.7141 - mae: 381.2399 - val_loss: 433169.0938 - val_mae: 380.8982\n",
      "Epoch 292/500\n",
      "1407/1407 [==============================] - 1s 770us/step - loss: 423755.3433 - mae: 380.8628 - val_loss: 432973.9375 - val_mae: 380.9782\n",
      "Epoch 293/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 438144.9279 - mae: 385.6459 - val_loss: 433069.3125 - val_mae: 380.7430\n",
      "Epoch 294/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 430171.6093 - mae: 381.9499 - val_loss: 433072.9375 - val_mae: 381.1288\n",
      "Epoch 295/500\n",
      "1407/1407 [==============================] - 1s 854us/step - loss: 427728.9622 - mae: 382.3318 - val_loss: 433178.6562 - val_mae: 381.1126\n",
      "Epoch 296/500\n",
      "1407/1407 [==============================] - 1s 792us/step - loss: 429288.9433 - mae: 381.5518 - val_loss: 432953.8438 - val_mae: 381.3492\n",
      "Epoch 297/500\n",
      "1407/1407 [==============================] - 1s 759us/step - loss: 437412.3715 - mae: 383.4577 - val_loss: 433303.5312 - val_mae: 381.2767\n",
      "Epoch 298/500\n",
      "1407/1407 [==============================] - 1s 731us/step - loss: 422362.5147 - mae: 379.9084 - val_loss: 432976.6562 - val_mae: 380.9272\n",
      "Epoch 299/500\n",
      "1407/1407 [==============================] - 1s 722us/step - loss: 425059.1185 - mae: 381.6626 - val_loss: 433081.7812 - val_mae: 381.2626\n",
      "Epoch 300/500\n",
      "1407/1407 [==============================] - 1s 744us/step - loss: 431475.1004 - mae: 380.8278 - val_loss: 433120.8438 - val_mae: 381.1874\n",
      "Epoch 301/500\n",
      "1407/1407 [==============================] - 1s 811us/step - loss: 420303.6609 - mae: 379.7572 - val_loss: 432979.8125 - val_mae: 380.7296\n",
      "Epoch 302/500\n",
      "1407/1407 [==============================] - 1s 902us/step - loss: 426439.1824 - mae: 381.1667 - val_loss: 433374.0000 - val_mae: 381.7112\n",
      "Epoch 303/500\n",
      "1407/1407 [==============================] - 1s 865us/step - loss: 435920.0091 - mae: 380.3202 - val_loss: 432856.8125 - val_mae: 381.3018\n",
      "Epoch 304/500\n",
      "1407/1407 [==============================] - 1s 819us/step - loss: 438571.1005 - mae: 383.0056 - val_loss: 433241.9375 - val_mae: 380.9575\n",
      "Epoch 305/500\n",
      "1407/1407 [==============================] - 1s 749us/step - loss: 423889.7652 - mae: 379.5119 - val_loss: 432853.1875 - val_mae: 381.0451\n",
      "Epoch 306/500\n",
      "1407/1407 [==============================] - 1s 768us/step - loss: 429260.4324 - mae: 381.9997 - val_loss: 433261.5000 - val_mae: 381.4540\n",
      "Epoch 307/500\n",
      "1407/1407 [==============================] - 1s 767us/step - loss: 429789.8633 - mae: 381.5488 - val_loss: 433296.7188 - val_mae: 381.1273\n",
      "Epoch 308/500\n",
      "1407/1407 [==============================] - 1s 754us/step - loss: 438223.4295 - mae: 384.3451 - val_loss: 433029.7188 - val_mae: 380.7282\n",
      "Epoch 309/500\n",
      "1407/1407 [==============================] - 1s 748us/step - loss: 430689.0585 - mae: 379.8778 - val_loss: 433010.8125 - val_mae: 381.3336\n",
      "Epoch 310/500\n",
      "1407/1407 [==============================] - 1s 753us/step - loss: 423734.8365 - mae: 380.2374 - val_loss: 432925.7812 - val_mae: 381.5233\n",
      "Epoch 311/500\n",
      "1407/1407 [==============================] - 1s 767us/step - loss: 433574.0564 - mae: 383.8447 - val_loss: 432977.2188 - val_mae: 380.7455\n",
      "Epoch 312/500\n",
      "1407/1407 [==============================] - 1s 775us/step - loss: 428485.2179 - mae: 380.0742 - val_loss: 433207.7500 - val_mae: 381.1285\n",
      "Epoch 313/500\n",
      "1407/1407 [==============================] - 1s 776us/step - loss: 431790.3474 - mae: 381.9390 - val_loss: 433040.3125 - val_mae: 380.9411\n",
      "Epoch 314/500\n",
      "1407/1407 [==============================] - 1s 769us/step - loss: 429252.2978 - mae: 383.1477 - val_loss: 432873.7812 - val_mae: 381.1557\n",
      "Epoch 315/500\n",
      "1407/1407 [==============================] - 1s 791us/step - loss: 438654.2160 - mae: 383.5069 - val_loss: 433148.3125 - val_mae: 381.0340\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 1s 733us/step - loss: 432920.9284 - mae: 382.1384 - val_loss: 432949.4375 - val_mae: 381.3002\n",
      "Epoch 317/500\n",
      "1407/1407 [==============================] - 1s 709us/step - loss: 430073.6297 - mae: 382.4984 - val_loss: 432945.0000 - val_mae: 380.8322\n",
      "Epoch 318/500\n",
      "1407/1407 [==============================] - 1s 725us/step - loss: 443095.0549 - mae: 384.1736 - val_loss: 432732.0000 - val_mae: 380.7784\n",
      "Epoch 319/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 433455.4061 - mae: 382.6369 - val_loss: 432996.7500 - val_mae: 381.0539\n",
      "Epoch 320/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 422574.6406 - mae: 381.3750 - val_loss: 432961.1250 - val_mae: 380.7129\n",
      "Epoch 321/500\n",
      "1407/1407 [==============================] - 1s 714us/step - loss: 431306.8612 - mae: 382.6759 - val_loss: 433134.0000 - val_mae: 381.4374\n",
      "Epoch 322/500\n",
      "1407/1407 [==============================] - 1s 723us/step - loss: 437243.2038 - mae: 382.8851 - val_loss: 432955.4688 - val_mae: 380.9024\n",
      "Epoch 323/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 432063.1740 - mae: 382.6368 - val_loss: 432886.9375 - val_mae: 380.9943\n",
      "Epoch 324/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 433522.6161 - mae: 383.0779 - val_loss: 432978.3125 - val_mae: 380.9808\n",
      "Epoch 325/500\n",
      "1407/1407 [==============================] - 1s 706us/step - loss: 433025.3519 - mae: 383.4955 - val_loss: 432914.1562 - val_mae: 381.0347\n",
      "Epoch 326/500\n",
      "1407/1407 [==============================] - 1s 719us/step - loss: 438237.3633 - mae: 383.8405 - val_loss: 433005.6250 - val_mae: 381.2507\n",
      "Epoch 327/500\n",
      "1407/1407 [==============================] - 1s 711us/step - loss: 428577.8791 - mae: 381.7768 - val_loss: 433014.7812 - val_mae: 380.8995\n",
      "Epoch 328/500\n",
      "1407/1407 [==============================] - 1s 713us/step - loss: 435664.5947 - mae: 382.2800 - val_loss: 432979.8438 - val_mae: 380.5781\n",
      "Epoch 329/500\n",
      "1407/1407 [==============================] - 1s 714us/step - loss: 429890.1355 - mae: 382.8039 - val_loss: 432866.8750 - val_mae: 381.2528\n",
      "Epoch 330/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 434938.5338 - mae: 384.3211 - val_loss: 432986.9062 - val_mae: 381.0122\n",
      "Epoch 331/500\n",
      "1407/1407 [==============================] - 1s 721us/step - loss: 418749.1857 - mae: 380.0304 - val_loss: 432791.3438 - val_mae: 381.0089\n",
      "Epoch 332/500\n",
      "1407/1407 [==============================] - 1s 724us/step - loss: 434277.5759 - mae: 381.7964 - val_loss: 433115.8125 - val_mae: 381.6695\n",
      "Epoch 333/500\n",
      "1407/1407 [==============================] - 1s 718us/step - loss: 430874.7110 - mae: 381.9034 - val_loss: 432727.6875 - val_mae: 381.2659\n",
      "Epoch 334/500\n",
      "1407/1407 [==============================] - 1s 728us/step - loss: 427170.5772 - mae: 380.4084 - val_loss: 432712.9375 - val_mae: 380.9927\n",
      "Epoch 335/500\n",
      "1407/1407 [==============================] - 1s 734us/step - loss: 430960.7680 - mae: 381.5243 - val_loss: 432868.6562 - val_mae: 380.8127\n",
      "Epoch 336/500\n",
      "1407/1407 [==============================] - 1s 725us/step - loss: 431153.9728 - mae: 382.2600 - val_loss: 432829.5938 - val_mae: 380.9101\n",
      "Epoch 337/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 429753.8049 - mae: 381.4572 - val_loss: 432735.4062 - val_mae: 381.0396\n",
      "Epoch 338/500\n",
      "1407/1407 [==============================] - 1s 762us/step - loss: 432591.8730 - mae: 382.7539 - val_loss: 432805.0312 - val_mae: 380.8214\n",
      "Epoch 339/500\n",
      "1407/1407 [==============================] - 1s 782us/step - loss: 430936.7202 - mae: 381.4628 - val_loss: 432929.0312 - val_mae: 380.8324\n",
      "Epoch 340/500\n",
      "1407/1407 [==============================] - 1s 852us/step - loss: 424733.3377 - mae: 380.5322 - val_loss: 433001.2500 - val_mae: 381.3993\n",
      "Epoch 341/500\n",
      "1407/1407 [==============================] - 1s 861us/step - loss: 432220.6754 - mae: 382.1956 - val_loss: 432920.1562 - val_mae: 381.1346\n",
      "Epoch 342/500\n",
      "1407/1407 [==============================] - 1s 907us/step - loss: 432281.1021 - mae: 381.7860 - val_loss: 432818.1875 - val_mae: 380.9558\n",
      "Epoch 343/500\n",
      "1407/1407 [==============================] - 1s 895us/step - loss: 421766.2615 - mae: 380.4531 - val_loss: 432934.4375 - val_mae: 380.8872\n",
      "Epoch 344/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 428040.0736 - mae: 380.4980 - val_loss: 432960.4062 - val_mae: 380.9947\n",
      "Epoch 345/500\n",
      "1407/1407 [==============================] - 1s 948us/step - loss: 425975.0587 - mae: 381.2568 - val_loss: 432899.7188 - val_mae: 381.3203\n",
      "Epoch 346/500\n",
      "1407/1407 [==============================] - 1s 842us/step - loss: 427484.9638 - mae: 380.6291 - val_loss: 432916.0312 - val_mae: 381.3242\n",
      "Epoch 347/500\n",
      "1407/1407 [==============================] - 1s 793us/step - loss: 426266.3904 - mae: 381.4820 - val_loss: 432816.3438 - val_mae: 380.7287\n",
      "Epoch 348/500\n",
      "1407/1407 [==============================] - 1s 755us/step - loss: 432854.3833 - mae: 382.6048 - val_loss: 432881.2812 - val_mae: 380.7758\n",
      "Epoch 349/500\n",
      "1407/1407 [==============================] - 1s 769us/step - loss: 423337.6770 - mae: 380.1714 - val_loss: 432793.3438 - val_mae: 381.1454\n",
      "Epoch 350/500\n",
      "1407/1407 [==============================] - 1s 764us/step - loss: 426917.3428 - mae: 379.9621 - val_loss: 432734.8750 - val_mae: 380.8432\n",
      "Epoch 351/500\n",
      "1407/1407 [==============================] - 1s 738us/step - loss: 437909.6252 - mae: 384.1239 - val_loss: 432761.4375 - val_mae: 380.5377\n",
      "Epoch 352/500\n",
      "1407/1407 [==============================] - 1s 791us/step - loss: 436786.3710 - mae: 384.4862 - val_loss: 432816.8125 - val_mae: 380.9040\n",
      "Epoch 353/500\n",
      "1407/1407 [==============================] - 1s 751us/step - loss: 426000.9357 - mae: 381.8663 - val_loss: 432777.1250 - val_mae: 381.0804\n",
      "Epoch 354/500\n",
      "1407/1407 [==============================] - 1s 800us/step - loss: 429023.9672 - mae: 380.0893 - val_loss: 432876.9375 - val_mae: 380.9744\n",
      "Epoch 355/500\n",
      "1407/1407 [==============================] - 1s 851us/step - loss: 424484.5987 - mae: 380.9591 - val_loss: 432794.2812 - val_mae: 380.6353\n",
      "Epoch 356/500\n",
      "1407/1407 [==============================] - 1s 838us/step - loss: 431874.5647 - mae: 381.0414 - val_loss: 432908.5625 - val_mae: 381.1975\n",
      "Epoch 357/500\n",
      "1407/1407 [==============================] - 1s 758us/step - loss: 436322.8277 - mae: 384.4484 - val_loss: 432840.4688 - val_mae: 380.9933\n",
      "Epoch 358/500\n",
      "1407/1407 [==============================] - 1s 736us/step - loss: 441833.2960 - mae: 384.7116 - val_loss: 432863.8750 - val_mae: 380.9173\n",
      "Epoch 359/500\n",
      "1407/1407 [==============================] - 1s 740us/step - loss: 443407.5906 - mae: 382.8198 - val_loss: 432854.1250 - val_mae: 381.0722\n",
      "Epoch 360/500\n",
      "1407/1407 [==============================] - 1s 780us/step - loss: 427189.4093 - mae: 381.1122 - val_loss: 432817.0625 - val_mae: 380.7795\n",
      "Epoch 361/500\n",
      "1407/1407 [==============================] - 1s 817us/step - loss: 442325.0851 - mae: 384.2641 - val_loss: 432892.5625 - val_mae: 380.6317\n",
      "Epoch 362/500\n",
      "1407/1407 [==============================] - 1s 830us/step - loss: 419782.9986 - mae: 379.9243 - val_loss: 432938.8125 - val_mae: 381.2142\n",
      "Epoch 363/500\n",
      "1407/1407 [==============================] - 1s 851us/step - loss: 429135.9179 - mae: 380.5541 - val_loss: 432820.0000 - val_mae: 380.8588\n",
      "Epoch 364/500\n",
      "1407/1407 [==============================] - 1s 835us/step - loss: 427241.7670 - mae: 380.7092 - val_loss: 432752.4062 - val_mae: 380.9405\n",
      "Epoch 365/500\n",
      "1407/1407 [==============================] - 1s 849us/step - loss: 434558.7287 - mae: 382.4843 - val_loss: 432697.7812 - val_mae: 380.9214\n",
      "Epoch 366/500\n",
      "1407/1407 [==============================] - 1s 814us/step - loss: 426574.5919 - mae: 381.6437 - val_loss: 432843.7188 - val_mae: 380.8989\n",
      "Epoch 367/500\n",
      "1407/1407 [==============================] - 1s 817us/step - loss: 432770.7284 - mae: 382.3620 - val_loss: 432875.6250 - val_mae: 381.1360\n",
      "Epoch 368/500\n",
      "1407/1407 [==============================] - 1s 823us/step - loss: 429472.8252 - mae: 381.8417 - val_loss: 432903.2812 - val_mae: 381.2634\n",
      "Epoch 369/500\n",
      "1407/1407 [==============================] - 1s 797us/step - loss: 431287.8523 - mae: 381.5935 - val_loss: 432777.8750 - val_mae: 380.9118\n",
      "Epoch 370/500\n",
      "1407/1407 [==============================] - 1s 808us/step - loss: 424567.5817 - mae: 379.3510 - val_loss: 432840.3438 - val_mae: 380.9670\n",
      "Epoch 371/500\n",
      "1407/1407 [==============================] - 1s 775us/step - loss: 436309.0892 - mae: 381.6922 - val_loss: 432827.1562 - val_mae: 380.9740\n",
      "Epoch 372/500\n",
      "1407/1407 [==============================] - 1s 794us/step - loss: 430503.3058 - mae: 380.9553 - val_loss: 432759.7500 - val_mae: 381.0505\n",
      "Epoch 373/500\n",
      "1407/1407 [==============================] - 1s 779us/step - loss: 423790.7119 - mae: 380.3376 - val_loss: 432791.0000 - val_mae: 380.8319\n",
      "Epoch 374/500\n",
      "1407/1407 [==============================] - 1s 757us/step - loss: 422253.5761 - mae: 380.8085 - val_loss: 432667.7188 - val_mae: 380.8225\n",
      "Epoch 375/500\n",
      "1407/1407 [==============================] - 1s 782us/step - loss: 422011.7164 - mae: 379.6161 - val_loss: 432782.4688 - val_mae: 380.7565\n",
      "Epoch 376/500\n",
      "1407/1407 [==============================] - 1s 794us/step - loss: 434227.1595 - mae: 382.1221 - val_loss: 432861.1562 - val_mae: 380.9331\n",
      "Epoch 377/500\n",
      "1407/1407 [==============================] - 1s 806us/step - loss: 441397.3207 - mae: 384.0408 - val_loss: 432775.7188 - val_mae: 381.0365\n",
      "Epoch 378/500\n",
      "1407/1407 [==============================] - 1s 794us/step - loss: 441428.2462 - mae: 384.1715 - val_loss: 432809.0000 - val_mae: 381.0804\n",
      "Epoch 379/500\n",
      "1407/1407 [==============================] - 1s 786us/step - loss: 438788.7656 - mae: 383.2579 - val_loss: 432800.8125 - val_mae: 381.1935\n",
      "Epoch 380/500\n",
      "1407/1407 [==============================] - 1s 773us/step - loss: 434222.7323 - mae: 382.7337 - val_loss: 432853.6562 - val_mae: 381.0538\n",
      "Epoch 381/500\n",
      "1407/1407 [==============================] - 1s 784us/step - loss: 429207.8758 - mae: 382.9420 - val_loss: 432779.1875 - val_mae: 381.0495\n",
      "Epoch 382/500\n",
      "1407/1407 [==============================] - 1s 796us/step - loss: 429588.1318 - mae: 381.0125 - val_loss: 432819.1250 - val_mae: 380.9556\n",
      "Epoch 383/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 436214.7417 - mae: 381.7435 - val_loss: 432834.9375 - val_mae: 380.8844\n",
      "Epoch 384/500\n",
      "1407/1407 [==============================] - 1s 869us/step - loss: 431593.4769 - mae: 383.0313 - val_loss: 432883.9375 - val_mae: 380.8275\n",
      "Epoch 385/500\n",
      "1407/1407 [==============================] - 1s 791us/step - loss: 424759.4853 - mae: 380.6264 - val_loss: 432795.6562 - val_mae: 381.0882\n",
      "Epoch 386/500\n",
      "1407/1407 [==============================] - 1s 752us/step - loss: 436164.1783 - mae: 382.1843 - val_loss: 432817.6562 - val_mae: 380.9942\n",
      "Epoch 387/500\n",
      "1407/1407 [==============================] - 1s 781us/step - loss: 432226.4215 - mae: 381.3527 - val_loss: 432789.7500 - val_mae: 380.8912\n",
      "Epoch 388/500\n",
      "1407/1407 [==============================] - 1s 751us/step - loss: 432223.2278 - mae: 383.3870 - val_loss: 432755.7812 - val_mae: 380.9418\n",
      "Epoch 389/500\n",
      "1407/1407 [==============================] - 1s 767us/step - loss: 442108.5394 - mae: 382.7030 - val_loss: 432795.5000 - val_mae: 380.8969\n",
      "Epoch 390/500\n",
      "1407/1407 [==============================] - 1s 776us/step - loss: 431369.4529 - mae: 381.6025 - val_loss: 432816.8125 - val_mae: 381.1161\n",
      "Epoch 391/500\n",
      "1407/1407 [==============================] - 1s 778us/step - loss: 427977.1043 - mae: 381.1655 - val_loss: 432830.0938 - val_mae: 381.0867\n",
      "Epoch 392/500\n",
      "1407/1407 [==============================] - 1s 774us/step - loss: 434133.2683 - mae: 382.6285 - val_loss: 432797.0312 - val_mae: 380.7155\n",
      "Epoch 393/500\n",
      "1407/1407 [==============================] - 1s 742us/step - loss: 437197.2781 - mae: 383.4866 - val_loss: 432765.0000 - val_mae: 380.9867\n",
      "Epoch 394/500\n",
      "1407/1407 [==============================] - 1s 748us/step - loss: 429720.1353 - mae: 382.5029 - val_loss: 432826.0625 - val_mae: 380.9633\n",
      "Epoch 395/500\n",
      "1407/1407 [==============================] - 1s 764us/step - loss: 433129.4956 - mae: 383.5275 - val_loss: 432769.1562 - val_mae: 380.9378\n",
      "Epoch 396/500\n",
      "1407/1407 [==============================] - 1s 743us/step - loss: 433679.8024 - mae: 382.9453 - val_loss: 432787.8750 - val_mae: 380.8800\n",
      "Epoch 397/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 433913.6990 - mae: 382.7490 - val_loss: 432770.2812 - val_mae: 380.8679\n",
      "Epoch 398/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 432273.0560 - mae: 383.2047 - val_loss: 432772.4688 - val_mae: 380.9636\n",
      "Epoch 399/500\n",
      "1407/1407 [==============================] - 1s 720us/step - loss: 433590.8239 - mae: 382.8442 - val_loss: 432749.6562 - val_mae: 380.8864\n",
      "Epoch 400/500\n",
      "1407/1407 [==============================] - 1s 748us/step - loss: 437924.9942 - mae: 383.3158 - val_loss: 432795.1875 - val_mae: 380.9102\n",
      "Epoch 401/500\n",
      "1407/1407 [==============================] - 1s 726us/step - loss: 424340.8911 - mae: 381.3921 - val_loss: 432751.0312 - val_mae: 380.9628\n",
      "Epoch 402/500\n",
      "1407/1407 [==============================] - 1s 738us/step - loss: 430747.3878 - mae: 381.2128 - val_loss: 432773.5000 - val_mae: 380.9762\n",
      "Epoch 403/500\n",
      "1407/1407 [==============================] - 1s 750us/step - loss: 436500.0164 - mae: 382.6959 - val_loss: 432739.3750 - val_mae: 380.9100\n",
      "Epoch 404/500\n",
      "1407/1407 [==============================] - 1s 859us/step - loss: 441770.7923 - mae: 384.8151 - val_loss: 432794.4062 - val_mae: 381.1007\n",
      "Epoch 405/500\n",
      "1407/1407 [==============================] - 1s 768us/step - loss: 435479.9754 - mae: 384.2899 - val_loss: 432758.3125 - val_mae: 380.8725\n",
      "Epoch 406/500\n",
      "1407/1407 [==============================] - 1s 758us/step - loss: 432787.7825 - mae: 381.2904 - val_loss: 432748.3750 - val_mae: 380.8990\n",
      "Epoch 407/500\n",
      "1407/1407 [==============================] - 1s 742us/step - loss: 433495.7696 - mae: 381.1183 - val_loss: 432735.8125 - val_mae: 380.9989\n",
      "Epoch 408/500\n",
      "1407/1407 [==============================] - 1s 733us/step - loss: 444901.6765 - mae: 383.7758 - val_loss: 432750.4375 - val_mae: 380.9857\n",
      "Epoch 409/500\n",
      "1407/1407 [==============================] - 1s 839us/step - loss: 436173.4460 - mae: 382.7035 - val_loss: 432762.6250 - val_mae: 380.9640\n",
      "Epoch 410/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 431714.1374 - mae: 380.3361 - val_loss: 432771.5000 - val_mae: 380.9272\n",
      "Epoch 411/500\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 432423.3554 - mae: 381.6015 - val_loss: 432775.8750 - val_mae: 380.9058\n",
      "Epoch 412/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 422888.6803 - mae: 381.1715 - val_loss: 432730.1250 - val_mae: 380.9636\n",
      "Epoch 413/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 429071.1060 - mae: 381.4005 - val_loss: 432749.4062 - val_mae: 380.7483\n",
      "Epoch 414/500\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 431915.0968 - mae: 381.4832 - val_loss: 432764.5000 - val_mae: 380.8095\n",
      "Epoch 415/500\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 439350.7739 - mae: 382.5024 - val_loss: 432750.6250 - val_mae: 380.9476\n",
      "Epoch 416/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 429973.6967 - mae: 382.3328 - val_loss: 432742.4688 - val_mae: 380.8833\n",
      "Epoch 417/500\n",
      "1407/1407 [==============================] - 1s 920us/step - loss: 434972.3399 - mae: 382.5040 - val_loss: 432739.2188 - val_mae: 380.9692\n",
      "Epoch 418/500\n",
      "1407/1407 [==============================] - 1s 832us/step - loss: 438920.1882 - mae: 383.6753 - val_loss: 432754.2188 - val_mae: 380.9531\n",
      "Epoch 419/500\n",
      "1407/1407 [==============================] - 1s 879us/step - loss: 438693.5030 - mae: 383.8649 - val_loss: 432750.4375 - val_mae: 380.8510\n",
      "Epoch 420/500\n",
      "1407/1407 [==============================] - 1s 806us/step - loss: 428225.8581 - mae: 382.4767 - val_loss: 432749.2188 - val_mae: 380.9852\n",
      "Epoch 421/500\n",
      "1407/1407 [==============================] - 1s 772us/step - loss: 425797.1405 - mae: 380.7555 - val_loss: 432730.7500 - val_mae: 380.8729\n",
      "Epoch 422/500\n",
      "1407/1407 [==============================] - 1s 778us/step - loss: 438078.2361 - mae: 382.9405 - val_loss: 432751.4688 - val_mae: 380.7399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/500\n",
      "1407/1407 [==============================] - 1s 765us/step - loss: 435814.6867 - mae: 382.9914 - val_loss: 432725.5625 - val_mae: 380.9301\n",
      "Epoch 424/500\n",
      "1407/1407 [==============================] - 1s 767us/step - loss: 430673.8442 - mae: 382.9216 - val_loss: 432759.8750 - val_mae: 380.7569\n",
      "Epoch 425/500\n",
      "1407/1407 [==============================] - 1s 787us/step - loss: 432660.3755 - mae: 381.8746 - val_loss: 432747.4062 - val_mae: 380.9641\n",
      "Epoch 426/500\n",
      "1407/1407 [==============================] - 1s 784us/step - loss: 433441.0222 - mae: 381.6420 - val_loss: 432755.4375 - val_mae: 380.9845\n",
      "Epoch 427/500\n",
      "1407/1407 [==============================] - 1s 771us/step - loss: 443668.9919 - mae: 383.7542 - val_loss: 432763.7812 - val_mae: 381.0788\n",
      "Epoch 428/500\n",
      "1407/1407 [==============================] - 1s 767us/step - loss: 425466.7718 - mae: 380.8648 - val_loss: 432739.7500 - val_mae: 381.0245\n",
      "Epoch 429/500\n",
      "1407/1407 [==============================] - 1s 770us/step - loss: 436375.1992 - mae: 382.2648 - val_loss: 432740.9062 - val_mae: 380.9077\n",
      "Epoch 430/500\n",
      "1407/1407 [==============================] - 1s 798us/step - loss: 443061.2890 - mae: 384.8270 - val_loss: 432750.2188 - val_mae: 380.9749\n",
      "Epoch 431/500\n",
      "1407/1407 [==============================] - 1s 743us/step - loss: 431919.0328 - mae: 382.9582 - val_loss: 432737.6562 - val_mae: 380.9961\n",
      "Epoch 432/500\n",
      "1407/1407 [==============================] - 1s 705us/step - loss: 431330.1939 - mae: 382.1982 - val_loss: 432740.5000 - val_mae: 380.9940\n",
      "Epoch 433/500\n",
      "1407/1407 [==============================] - 1s 737us/step - loss: 432889.2039 - mae: 382.1492 - val_loss: 432742.3750 - val_mae: 380.9829\n",
      "Epoch 434/500\n",
      "1407/1407 [==============================] - 1s 729us/step - loss: 427775.8716 - mae: 382.0311 - val_loss: 432718.4062 - val_mae: 380.8331\n",
      "Epoch 435/500\n",
      "1407/1407 [==============================] - 1s 763us/step - loss: 430484.5587 - mae: 381.3975 - val_loss: 432739.3438 - val_mae: 380.8781\n",
      "Epoch 436/500\n",
      "1407/1407 [==============================] - 1s 743us/step - loss: 431151.8399 - mae: 383.9104 - val_loss: 432717.5938 - val_mae: 380.8360\n",
      "Epoch 437/500\n",
      "1407/1407 [==============================] - 1s 920us/step - loss: 436315.4639 - mae: 382.6757 - val_loss: 432716.9688 - val_mae: 380.8480\n",
      "Epoch 438/500\n",
      "1407/1407 [==============================] - 1s 934us/step - loss: 435845.5536 - mae: 383.4898 - val_loss: 432719.7500 - val_mae: 380.9720\n",
      "Epoch 439/500\n",
      "1407/1407 [==============================] - 1s 837us/step - loss: 424688.7995 - mae: 380.7754 - val_loss: 432716.4688 - val_mae: 380.8598\n",
      "Epoch 440/500\n",
      "1407/1407 [==============================] - 1s 813us/step - loss: 430745.9270 - mae: 382.1850 - val_loss: 432714.6875 - val_mae: 380.8927\n",
      "Epoch 441/500\n",
      "1407/1407 [==============================] - 1s 955us/step - loss: 430278.6331 - mae: 381.4801 - val_loss: 432703.9062 - val_mae: 380.9180\n",
      "Epoch 442/500\n",
      "1407/1407 [==============================] - 1s 892us/step - loss: 433590.6971 - mae: 382.3722 - val_loss: 432700.9062 - val_mae: 380.9924\n",
      "Epoch 443/500\n",
      "1407/1407 [==============================] - 1s 783us/step - loss: 434736.1494 - mae: 382.6093 - val_loss: 432705.5312 - val_mae: 380.8926\n",
      "Epoch 444/500\n",
      "1407/1407 [==============================] - 1s 755us/step - loss: 431860.3914 - mae: 381.6605 - val_loss: 432716.4375 - val_mae: 380.9578\n",
      "Epoch 445/500\n",
      "1407/1407 [==============================] - 1s 745us/step - loss: 430948.4260 - mae: 382.2723 - val_loss: 432712.1562 - val_mae: 380.9043\n",
      "Epoch 446/500\n",
      "1407/1407 [==============================] - 1s 774us/step - loss: 425205.0841 - mae: 379.7531 - val_loss: 432714.3438 - val_mae: 380.8512\n",
      "Epoch 447/500\n",
      "1407/1407 [==============================] - 1s 957us/step - loss: 431807.2226 - mae: 382.4720 - val_loss: 432711.0312 - val_mae: 380.8399\n",
      "Epoch 448/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 429983.5532 - mae: 382.8841 - val_loss: 432711.7500 - val_mae: 380.8174\n",
      "Epoch 449/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 437252.2116 - mae: 384.8095 - val_loss: 432711.2812 - val_mae: 380.8261\n",
      "Epoch 450/500\n",
      "1407/1407 [==============================] - 2s 1ms/step - loss: 431438.7444 - mae: 380.8013 - val_loss: 432707.3438 - val_mae: 380.8845\n",
      "Epoch 451/500\n",
      "1407/1407 [==============================] - 1s 897us/step - loss: 433378.0529 - mae: 382.6977 - val_loss: 432704.4062 - val_mae: 380.8387\n",
      "Epoch 452/500\n",
      "1407/1407 [==============================] - 1s 949us/step - loss: 435580.2273 - mae: 382.2190 - val_loss: 432709.8438 - val_mae: 380.8059\n",
      "Epoch 453/500\n",
      "1407/1407 [==============================] - 1s 998us/step - loss: 438505.3041 - mae: 382.9531 - val_loss: 432710.9062 - val_mae: 380.8222\n",
      "Epoch 454/500\n",
      "1407/1407 [==============================] - 1s 995us/step - loss: 445213.1700 - mae: 383.4389 - val_loss: 432716.0312 - val_mae: 380.9009\n",
      "Epoch 455/500\n",
      "1407/1407 [==============================] - 1s 1ms/step - loss: 435974.8882 - mae: 382.6460 - val_loss: 432713.6562 - val_mae: 380.8916\n",
      "Epoch 456/500\n",
      "1407/1407 [==============================] - 1s 972us/step - loss: 425271.4304 - mae: 381.2588 - val_loss: 432708.0938 - val_mae: 380.8948\n",
      "Epoch 457/500\n",
      "1407/1407 [==============================] - 1s 980us/step - loss: 432828.8635 - mae: 381.1773 - val_loss: 432713.9062 - val_mae: 380.9358\n",
      "Epoch 458/500\n",
      "1407/1407 [==============================] - 1s 944us/step - loss: 430101.6188 - mae: 380.6728 - val_loss: 432722.0938 - val_mae: 380.9094\n",
      "Epoch 459/500\n",
      "1407/1407 [==============================] - 1s 843us/step - loss: 431397.0302 - mae: 383.7348 - val_loss: 432725.8438 - val_mae: 380.9503\n",
      "Epoch 460/500\n",
      "1407/1407 [==============================] - 1s 908us/step - loss: 439337.7399 - mae: 383.2247 - val_loss: 432725.8750 - val_mae: 380.9288\n",
      "Epoch 461/500\n",
      "1407/1407 [==============================] - 1s 862us/step - loss: 432198.7234 - mae: 382.2416 - val_loss: 432716.8750 - val_mae: 380.8882\n",
      "Epoch 462/500\n",
      "1407/1407 [==============================] - 1s 778us/step - loss: 428159.1656 - mae: 384.2251 - val_loss: 432718.0312 - val_mae: 380.9569\n",
      "Epoch 463/500\n",
      "1407/1407 [==============================] - 1s 781us/step - loss: 432627.8767 - mae: 381.3301 - val_loss: 432706.8750 - val_mae: 380.9313\n",
      "Epoch 464/500\n",
      "1407/1407 [==============================] - 1s 701us/step - loss: 427586.5882 - mae: 380.6648 - val_loss: 432705.0312 - val_mae: 380.9143\n",
      "Epoch 465/500\n",
      "1407/1407 [==============================] - 1s 706us/step - loss: 429226.9953 - mae: 381.4069 - val_loss: 432706.4688 - val_mae: 380.8967\n",
      "Epoch 466/500\n",
      "1407/1407 [==============================] - 1s 706us/step - loss: 427052.9861 - mae: 380.7106 - val_loss: 432701.4688 - val_mae: 380.9001\n",
      "Epoch 467/500\n",
      "1407/1407 [==============================] - 1s 712us/step - loss: 426306.1719 - mae: 381.5489 - val_loss: 432702.7188 - val_mae: 380.8178\n",
      "Epoch 468/500\n",
      "1407/1407 [==============================] - 1s 717us/step - loss: 432315.5555 - mae: 382.3173 - val_loss: 432714.0000 - val_mae: 380.8256\n",
      "Epoch 469/500\n",
      "1407/1407 [==============================] - 1s 719us/step - loss: 434861.0363 - mae: 381.7042 - val_loss: 432711.4062 - val_mae: 380.8632\n",
      "Epoch 470/500\n",
      "1407/1407 [==============================] - 1s 848us/step - loss: 430885.6962 - mae: 381.6004 - val_loss: 432712.9062 - val_mae: 380.8582\n",
      "Epoch 471/500\n",
      "1407/1407 [==============================] - 1s 1ms/step - loss: 442312.7513 - mae: 383.6137 - val_loss: 432709.0625 - val_mae: 380.8813\n",
      "Epoch 472/500\n",
      "1407/1407 [==============================] - 1s 983us/step - loss: 423389.1347 - mae: 380.5435 - val_loss: 432705.0312 - val_mae: 380.8815\n",
      "Epoch 473/500\n",
      "1407/1407 [==============================] - 1s 904us/step - loss: 427326.4766 - mae: 380.8744 - val_loss: 432709.1250 - val_mae: 380.9338\n",
      "Epoch 474/500\n",
      "1407/1407 [==============================] - 1s 964us/step - loss: 422772.5803 - mae: 380.3000 - val_loss: 432701.5312 - val_mae: 380.9179\n",
      "Epoch 475/500\n",
      "1407/1407 [==============================] - 1s 940us/step - loss: 434040.9115 - mae: 382.5914 - val_loss: 432702.6562 - val_mae: 380.8502\n",
      "Epoch 476/500\n",
      "1407/1407 [==============================] - 1s 854us/step - loss: 423248.2166 - mae: 380.1246 - val_loss: 432707.3125 - val_mae: 380.8923\n",
      "Epoch 477/500\n",
      "1407/1407 [==============================] - 1s 898us/step - loss: 427541.8025 - mae: 383.6534 - val_loss: 432711.2188 - val_mae: 380.8195\n",
      "Epoch 478/500\n",
      "1407/1407 [==============================] - 1s 906us/step - loss: 431879.2336 - mae: 382.8611 - val_loss: 432711.7500 - val_mae: 380.8912\n",
      "Epoch 479/500\n",
      "1407/1407 [==============================] - 1s 852us/step - loss: 432578.8746 - mae: 383.3907 - val_loss: 432710.1250 - val_mae: 380.8706\n",
      "Epoch 480/500\n",
      "1407/1407 [==============================] - 1s 766us/step - loss: 429617.9374 - mae: 380.0532 - val_loss: 432712.4062 - val_mae: 380.8924\n",
      "Epoch 481/500\n",
      "1407/1407 [==============================] - 1s 793us/step - loss: 426493.8631 - mae: 380.7742 - val_loss: 432709.7500 - val_mae: 380.8917\n",
      "Epoch 482/500\n",
      "1407/1407 [==============================] - 1s 721us/step - loss: 423216.7360 - mae: 380.2332 - val_loss: 432705.5000 - val_mae: 380.8602\n",
      "Epoch 483/500\n",
      "1407/1407 [==============================] - 1s 732us/step - loss: 433333.3851 - mae: 381.3307 - val_loss: 432711.1562 - val_mae: 380.8398\n",
      "Epoch 484/500\n",
      "1407/1407 [==============================] - 1s 749us/step - loss: 417665.7471 - mae: 378.3685 - val_loss: 432713.1562 - val_mae: 380.9302\n",
      "Epoch 485/500\n",
      "1407/1407 [==============================] - 1s 702us/step - loss: 427518.8199 - mae: 380.4735 - val_loss: 432711.0938 - val_mae: 380.9790\n",
      "Epoch 486/500\n",
      "1407/1407 [==============================] - 1s 853us/step - loss: 421103.0409 - mae: 380.3877 - val_loss: 432711.5938 - val_mae: 380.8967\n",
      "Epoch 487/500\n",
      "1407/1407 [==============================] - 1s 922us/step - loss: 423153.8637 - mae: 379.9845 - val_loss: 432704.4688 - val_mae: 380.9031\n",
      "Epoch 488/500\n",
      "1407/1407 [==============================] - 1s 943us/step - loss: 428078.6453 - mae: 381.7516 - val_loss: 432702.6562 - val_mae: 380.8965\n",
      "Epoch 489/500\n",
      "1407/1407 [==============================] - 1s 970us/step - loss: 432192.6906 - mae: 382.3414 - val_loss: 432707.9062 - val_mae: 380.8794\n",
      "Epoch 490/500\n",
      "1407/1407 [==============================] - 1s 772us/step - loss: 434205.9972 - mae: 382.1439 - val_loss: 432700.5938 - val_mae: 380.8905\n",
      "Epoch 491/500\n",
      "1407/1407 [==============================] - 1s 735us/step - loss: 430792.3716 - mae: 380.2534 - val_loss: 432708.7500 - val_mae: 380.8667\n",
      "Epoch 492/500\n",
      "1407/1407 [==============================] - 1s 830us/step - loss: 428691.6105 - mae: 380.2873 - val_loss: 432704.8438 - val_mae: 380.9021\n",
      "Epoch 493/500\n",
      "1407/1407 [==============================] - 1s 886us/step - loss: 429701.8822 - mae: 380.0941 - val_loss: 432706.7188 - val_mae: 380.8744\n",
      "Epoch 494/500\n",
      "1407/1407 [==============================] - 1s 856us/step - loss: 431905.7818 - mae: 379.9980 - val_loss: 432710.8750 - val_mae: 380.8771\n",
      "Epoch 495/500\n",
      "1407/1407 [==============================] - 1s 893us/step - loss: 428832.3171 - mae: 381.0605 - val_loss: 432709.8125 - val_mae: 380.8889\n",
      "Epoch 496/500\n",
      "1407/1407 [==============================] - 1s 996us/step - loss: 443472.9334 - mae: 384.1989 - val_loss: 432708.5312 - val_mae: 380.8657\n",
      "Epoch 497/500\n",
      "1407/1407 [==============================] - 1s 842us/step - loss: 426102.9980 - mae: 381.1599 - val_loss: 432711.5625 - val_mae: 380.8667\n",
      "Epoch 498/500\n",
      "1407/1407 [==============================] - 1s 829us/step - loss: 429790.0127 - mae: 379.1281 - val_loss: 432711.0625 - val_mae: 380.8812\n",
      "Epoch 499/500\n",
      "1407/1407 [==============================] - 1s 749us/step - loss: 432921.0871 - mae: 382.0467 - val_loss: 432707.4375 - val_mae: 380.9055\n",
      "Epoch 500/500\n",
      "1407/1407 [==============================] - 1s 727us/step - loss: 436394.7899 - mae: 382.2394 - val_loss: 432706.0938 - val_mae: 380.8727\n",
      "INFO:tensorflow:Assets written to: PRICESTIANE1/assets\n"
     ]
    }
   ],
   "source": [
    " create_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f05b511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('PRICESTIANE1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7793ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14070/14070 [==============================] - 10s 686us/step - loss: 437423.5938 - mae: 386.3131 - val_loss: 433876.0312 - val_mae: 384.1993\n",
      "Epoch 2/100\n",
      "14070/14070 [==============================] - 10s 676us/step - loss: 437684.5312 - mae: 386.3795 - val_loss: 435289.0625 - val_mae: 383.1522\n",
      "Epoch 3/100\n",
      "14070/14070 [==============================] - 10s 682us/step - loss: 437166.7188 - mae: 386.3825 - val_loss: 438158.7188 - val_mae: 383.6781\n",
      "Epoch 4/100\n",
      "14070/14070 [==============================] - 10s 736us/step - loss: 436943.2500 - mae: 386.4558 - val_loss: 438840.5938 - val_mae: 389.0698\n",
      "Epoch 5/100\n",
      "14070/14070 [==============================] - 13s 919us/step - loss: 437203.2500 - mae: 386.0511 - val_loss: 436426.0000 - val_mae: 384.1165\n",
      "Epoch 6/100\n",
      "14070/14070 [==============================] - 10s 719us/step - loss: 436848.1875 - mae: 385.9986 - val_loss: 438450.7812 - val_mae: 386.8212\n",
      "Epoch 7/100\n",
      "14070/14070 [==============================] - 12s 843us/step - loss: 436691.5000 - mae: 385.9695 - val_loss: 438492.0625 - val_mae: 384.5321\n",
      "Epoch 8/100\n",
      "14070/14070 [==============================] - 10s 737us/step - loss: 436831.8438 - mae: 386.0785 - val_loss: 438565.3125 - val_mae: 382.0251\n",
      "Epoch 9/100\n",
      "14070/14070 [==============================] - 10s 735us/step - loss: 436661.3750 - mae: 385.8514 - val_loss: 445981.5625 - val_mae: 390.5139\n",
      "Epoch 10/100\n",
      "14070/14070 [==============================] - 11s 759us/step - loss: 436419.5938 - mae: 385.7036 - val_loss: 435868.6250 - val_mae: 385.8385\n",
      "Epoch 11/100\n",
      "14070/14070 [==============================] - 11s 770us/step - loss: 436579.4375 - mae: 385.7054 - val_loss: 435610.7188 - val_mae: 381.9853\n",
      "Epoch 12/100\n",
      "14070/14070 [==============================] - 10s 696us/step - loss: 436479.0625 - mae: 385.8713 - val_loss: 439757.8438 - val_mae: 386.6949\n",
      "Epoch 13/100\n",
      "14070/14070 [==============================] - 10s 700us/step - loss: 436421.1562 - mae: 385.7577 - val_loss: 435643.9062 - val_mae: 387.1974\n",
      "Epoch 14/100\n",
      "14070/14070 [==============================] - 10s 738us/step - loss: 436175.1562 - mae: 385.6964 - val_loss: 435548.7500 - val_mae: 385.4631\n",
      "Epoch 15/100\n",
      "14070/14070 [==============================] - 11s 793us/step - loss: 436135.8125 - mae: 385.3466 - val_loss: 433237.0938 - val_mae: 382.3709\n",
      "Epoch 16/100\n",
      "14070/14070 [==============================] - 12s 870us/step - loss: 436119.2188 - mae: 385.1795 - val_loss: 434048.7188 - val_mae: 384.2639\n",
      "Epoch 17/100\n",
      "14070/14070 [==============================] - 12s 851us/step - loss: 435413.9375 - mae: 385.4018 - val_loss: 434681.4688 - val_mae: 382.1906\n",
      "Epoch 18/100\n",
      "14070/14070 [==============================] - 11s 796us/step - loss: 435428.9062 - mae: 385.0485 - val_loss: 435689.0312 - val_mae: 383.3770\n",
      "Epoch 19/100\n",
      "14070/14070 [==============================] - 12s 875us/step - loss: 435620.9062 - mae: 384.9598 - val_loss: 433489.1562 - val_mae: 384.4430\n",
      "Epoch 20/100\n",
      "14070/14070 [==============================] - 11s 785us/step - loss: 435487.1250 - mae: 384.7594 - val_loss: 433369.1250 - val_mae: 381.8548\n",
      "Epoch 21/100\n",
      "14070/14070 [==============================] - 10s 704us/step - loss: 435296.3438 - mae: 384.7632 - val_loss: 432025.4688 - val_mae: 380.9701\n",
      "Epoch 22/100\n",
      "14070/14070 [==============================] - 11s 779us/step - loss: 435523.7500 - mae: 385.0143 - val_loss: 432452.5000 - val_mae: 380.8364\n",
      "Epoch 23/100\n",
      "14070/14070 [==============================] - 10s 743us/step - loss: 435245.3125 - mae: 384.6807 - val_loss: 436093.6875 - val_mae: 382.7989\n",
      "Epoch 24/100\n",
      "14070/14070 [==============================] - 13s 953us/step - loss: 434940.7812 - mae: 384.5389 - val_loss: 439718.2500 - val_mae: 383.3841\n",
      "Epoch 25/100\n",
      "14070/14070 [==============================] - 12s 887us/step - loss: 434824.2812 - mae: 384.5646 - val_loss: 437974.7812 - val_mae: 389.6293\n",
      "Epoch 26/100\n",
      "14070/14070 [==============================] - 11s 787us/step - loss: 434646.3438 - mae: 384.5563 - val_loss: 441167.6875 - val_mae: 385.0558\n",
      "Epoch 27/100\n",
      "14070/14070 [==============================] - 11s 763us/step - loss: 434490.4375 - mae: 384.0806 - val_loss: 431713.8438 - val_mae: 381.7854\n",
      "Epoch 28/100\n",
      "14070/14070 [==============================] - 13s 950us/step - loss: 434294.7812 - mae: 384.3571 - val_loss: 436560.6562 - val_mae: 386.1882\n",
      "Epoch 29/100\n",
      "14070/14070 [==============================] - 12s 835us/step - loss: 434336.0312 - mae: 384.6569 - val_loss: 431965.0000 - val_mae: 380.6539\n",
      "Epoch 30/100\n",
      "14070/14070 [==============================] - 12s 819us/step - loss: 434356.2500 - mae: 384.5731 - val_loss: 437327.1250 - val_mae: 383.8519\n",
      "Epoch 31/100\n",
      "14070/14070 [==============================] - 10s 723us/step - loss: 433870.0312 - mae: 384.0551 - val_loss: 433890.9688 - val_mae: 382.3721\n",
      "Epoch 32/100\n",
      "14070/14070 [==============================] - 14s 964us/step - loss: 434525.8438 - mae: 384.0739 - val_loss: 434044.2188 - val_mae: 380.0403\n",
      "Epoch 33/100\n",
      "14070/14070 [==============================] - 13s 939us/step - loss: 433916.1875 - mae: 383.9779 - val_loss: 437095.2812 - val_mae: 382.2895\n",
      "Epoch 34/100\n",
      "14070/14070 [==============================] - 13s 913us/step - loss: 433999.6875 - mae: 384.2832 - val_loss: 432311.0000 - val_mae: 379.3547\n",
      "Epoch 35/100\n",
      "14070/14070 [==============================] - 11s 762us/step - loss: 433735.4062 - mae: 384.0066 - val_loss: 435123.2188 - val_mae: 381.4818\n",
      "Epoch 36/100\n",
      "14070/14070 [==============================] - 10s 731us/step - loss: 433738.6875 - mae: 383.9336 - val_loss: 432842.5000 - val_mae: 382.9413\n",
      "Epoch 37/100\n",
      "14070/14070 [==============================] - 11s 774us/step - loss: 433625.5938 - mae: 383.9535 - val_loss: 432807.6875 - val_mae: 382.1489\n",
      "Epoch 38/100\n",
      "14070/14070 [==============================] - 13s 936us/step - loss: 433545.3438 - mae: 384.2315 - val_loss: 431922.2188 - val_mae: 383.3313\n",
      "Epoch 39/100\n",
      "14070/14070 [==============================] - 12s 839us/step - loss: 433669.3125 - mae: 383.9053 - val_loss: 431089.9375 - val_mae: 383.0114\n",
      "Epoch 40/100\n",
      "14070/14070 [==============================] - 11s 786us/step - loss: 433266.4062 - mae: 384.1169 - val_loss: 434586.7188 - val_mae: 383.3062\n",
      "Epoch 41/100\n",
      "14070/14070 [==============================] - 14s 988us/step - loss: 433426.8750 - mae: 383.6649 - val_loss: 434140.5625 - val_mae: 385.8547\n",
      "Epoch 42/100\n",
      "14070/14070 [==============================] - 14s 1ms/step - loss: 433005.2188 - mae: 383.7306 - val_loss: 434056.4062 - val_mae: 380.6324\n",
      "Epoch 43/100\n",
      "14070/14070 [==============================] - 11s 779us/step - loss: 433233.0625 - mae: 383.4189 - val_loss: 432293.8750 - val_mae: 382.9190\n",
      "Epoch 44/100\n",
      "14070/14070 [==============================] - 10s 693us/step - loss: 432597.0000 - mae: 383.6295 - val_loss: 434100.5312 - val_mae: 380.8463\n",
      "Epoch 45/100\n",
      "14070/14070 [==============================] - 12s 856us/step - loss: 433055.5000 - mae: 383.7795 - val_loss: 430774.7812 - val_mae: 379.9691\n",
      "Epoch 46/100\n",
      "14070/14070 [==============================] - 10s 725us/step - loss: 432705.4688 - mae: 383.5955 - val_loss: 433632.4688 - val_mae: 385.5209\n",
      "Epoch 47/100\n",
      "14070/14070 [==============================] - 12s 845us/step - loss: 432688.1875 - mae: 383.5319 - val_loss: 429802.8750 - val_mae: 378.8707\n",
      "Epoch 48/100\n",
      "14070/14070 [==============================] - 12s 853us/step - loss: 432640.9375 - mae: 383.3561 - val_loss: 431621.7188 - val_mae: 382.3474\n",
      "Epoch 49/100\n",
      "14070/14070 [==============================] - 12s 820us/step - loss: 432624.7812 - mae: 383.5586 - val_loss: 432196.6250 - val_mae: 379.4684\n",
      "Epoch 50/100\n",
      "14070/14070 [==============================] - 10s 697us/step - loss: 432502.3125 - mae: 383.4766 - val_loss: 433898.5625 - val_mae: 381.8615\n",
      "Epoch 51/100\n",
      "14070/14070 [==============================] - 13s 895us/step - loss: 431862.6562 - mae: 383.1735 - val_loss: 428309.3438 - val_mae: 381.2180\n",
      "Epoch 52/100\n",
      "14070/14070 [==============================] - 14s 988us/step - loss: 431939.7188 - mae: 383.1565 - val_loss: 434627.9375 - val_mae: 383.7731\n",
      "Epoch 53/100\n",
      "14070/14070 [==============================] - 11s 749us/step - loss: 432263.4062 - mae: 383.1364 - val_loss: 431213.0312 - val_mae: 381.5687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "14070/14070 [==============================] - 12s 835us/step - loss: 431658.3750 - mae: 383.1346 - val_loss: 430359.1562 - val_mae: 382.1324\n",
      "Epoch 55/100\n",
      "14070/14070 [==============================] - 11s 767us/step - loss: 431918.0625 - mae: 383.2887 - val_loss: 431970.0000 - val_mae: 381.7487\n",
      "Epoch 56/100\n",
      "14070/14070 [==============================] - 12s 838us/step - loss: 431691.3750 - mae: 383.1103 - val_loss: 436173.2812 - val_mae: 380.8292\n",
      "Epoch 57/100\n",
      "14070/14070 [==============================] - 12s 843us/step - loss: 431817.1250 - mae: 383.3241 - val_loss: 430518.8125 - val_mae: 384.8604\n",
      "Epoch 58/100\n",
      "14070/14070 [==============================] - 11s 799us/step - loss: 431071.8438 - mae: 382.6565 - val_loss: 430879.4688 - val_mae: 380.6905\n",
      "Epoch 59/100\n",
      "14070/14070 [==============================] - 12s 841us/step - loss: 431130.7500 - mae: 383.1484 - val_loss: 429011.5625 - val_mae: 379.5936\n",
      "Epoch 60/100\n",
      "14070/14070 [==============================] - 12s 877us/step - loss: 431435.6562 - mae: 382.9751 - val_loss: 430934.6562 - val_mae: 382.6191\n",
      "Epoch 61/100\n",
      "14070/14070 [==============================] - 12s 849us/step - loss: 431220.3125 - mae: 383.2380 - val_loss: 429065.2812 - val_mae: 380.5328\n",
      "Epoch 62/100\n",
      "14070/14070 [==============================] - 11s 792us/step - loss: 430811.5938 - mae: 382.6874 - val_loss: 428813.1562 - val_mae: 383.4796\n",
      "Epoch 63/100\n",
      "14070/14070 [==============================] - 11s 772us/step - loss: 431582.1562 - mae: 383.2690 - val_loss: 436005.5938 - val_mae: 385.0770\n",
      "Epoch 64/100\n",
      "14070/14070 [==============================] - 11s 785us/step - loss: 430730.7500 - mae: 382.7566 - val_loss: 440156.6250 - val_mae: 389.6421\n",
      "Epoch 65/100\n",
      "14070/14070 [==============================] - 13s 912us/step - loss: 430607.1875 - mae: 383.1454 - val_loss: 429503.7500 - val_mae: 378.9026\n",
      "Epoch 66/100\n",
      "14070/14070 [==============================] - 10s 721us/step - loss: 430796.9375 - mae: 383.0403 - val_loss: 428611.6562 - val_mae: 378.8436\n",
      "Epoch 67/100\n",
      "14070/14070 [==============================] - 10s 715us/step - loss: 430779.7812 - mae: 382.6585 - val_loss: 431308.8125 - val_mae: 381.9590\n",
      "Epoch 68/100\n",
      "14070/14070 [==============================] - 10s 681us/step - loss: 431023.8750 - mae: 382.6155 - val_loss: 427827.3438 - val_mae: 380.8512\n",
      "Epoch 69/100\n",
      "14070/14070 [==============================] - 9s 667us/step - loss: 430402.2812 - mae: 382.5927 - val_loss: 431832.7812 - val_mae: 381.8456\n",
      "Epoch 70/100\n",
      "14070/14070 [==============================] - 9s 670us/step - loss: 430326.9375 - mae: 382.6349 - val_loss: 430676.7812 - val_mae: 379.0774\n",
      "Epoch 71/100\n",
      "14070/14070 [==============================] - 9s 665us/step - loss: 430296.2500 - mae: 382.6826 - val_loss: 431407.6250 - val_mae: 380.5306\n",
      "Epoch 72/100\n",
      "14070/14070 [==============================] - 10s 677us/step - loss: 430653.5000 - mae: 382.9186 - val_loss: 427671.0000 - val_mae: 379.0116\n",
      "Epoch 73/100\n",
      "14070/14070 [==============================] - 11s 755us/step - loss: 429565.5312 - mae: 382.5487 - val_loss: 436077.2812 - val_mae: 385.4322\n",
      "Epoch 74/100\n",
      "14070/14070 [==============================] - 13s 909us/step - loss: 429816.8125 - mae: 382.9239 - val_loss: 428239.3750 - val_mae: 379.2638\n",
      "Epoch 75/100\n",
      "14070/14070 [==============================] - 13s 891us/step - loss: 429411.6875 - mae: 382.6002 - val_loss: 428869.4062 - val_mae: 384.3147\n",
      "Epoch 76/100\n",
      "14070/14070 [==============================] - 12s 837us/step - loss: 429730.7500 - mae: 382.6043 - val_loss: 436852.3438 - val_mae: 380.2693\n",
      "Epoch 77/100\n",
      "14070/14070 [==============================] - 13s 891us/step - loss: 429361.6562 - mae: 382.4032 - val_loss: 431268.6250 - val_mae: 382.3230\n",
      "Epoch 78/100\n",
      "14070/14070 [==============================] - 12s 842us/step - loss: 429393.4375 - mae: 382.8138 - val_loss: 429210.5312 - val_mae: 381.5052\n",
      "Epoch 79/100\n",
      "14070/14070 [==============================] - 12s 857us/step - loss: 429315.0625 - mae: 382.5349 - val_loss: 431848.2500 - val_mae: 382.8187\n",
      "Epoch 80/100\n",
      "14070/14070 [==============================] - 12s 865us/step - loss: 429465.3750 - mae: 382.4726 - val_loss: 427552.0312 - val_mae: 378.8912\n",
      "Epoch 81/100\n",
      "14070/14070 [==============================] - 13s 913us/step - loss: 429049.3125 - mae: 382.2524 - val_loss: 430424.1250 - val_mae: 379.4520\n",
      "Epoch 82/100\n",
      "14070/14070 [==============================] - 12s 826us/step - loss: 429556.3438 - mae: 382.0359 - val_loss: 429169.3438 - val_mae: 379.9128\n",
      "Epoch 83/100\n",
      "14070/14070 [==============================] - 11s 760us/step - loss: 428870.9375 - mae: 382.3426 - val_loss: 429665.0312 - val_mae: 385.0501\n",
      "Epoch 84/100\n",
      "14070/14070 [==============================] - 12s 858us/step - loss: 428762.8750 - mae: 382.1644 - val_loss: 428659.4375 - val_mae: 381.3133\n",
      "Epoch 85/100\n",
      "14070/14070 [==============================] - 11s 809us/step - loss: 429577.9688 - mae: 382.2284 - val_loss: 427289.7812 - val_mae: 378.3921\n",
      "Epoch 86/100\n",
      "14070/14070 [==============================] - 11s 813us/step - loss: 428832.5000 - mae: 382.3159 - val_loss: 429474.4062 - val_mae: 381.0029\n",
      "Epoch 87/100\n",
      "14070/14070 [==============================] - 12s 872us/step - loss: 428916.2812 - mae: 381.9081 - val_loss: 426358.0625 - val_mae: 380.6210\n",
      "Epoch 88/100\n",
      "14070/14070 [==============================] - 12s 818us/step - loss: 428889.3438 - mae: 381.8735 - val_loss: 428704.5312 - val_mae: 382.5105\n",
      "Epoch 89/100\n",
      "14070/14070 [==============================] - 11s 805us/step - loss: 428308.1562 - mae: 381.8354 - val_loss: 429967.9062 - val_mae: 377.8593\n",
      "Epoch 90/100\n",
      "14070/14070 [==============================] - 11s 788us/step - loss: 429303.5312 - mae: 382.2291 - val_loss: 427250.1562 - val_mae: 382.6089\n",
      "Epoch 91/100\n",
      "14070/14070 [==============================] - 11s 803us/step - loss: 428010.2500 - mae: 381.6972 - val_loss: 426663.1562 - val_mae: 379.1334\n",
      "Epoch 92/100\n",
      "14070/14070 [==============================] - 11s 797us/step - loss: 429170.0312 - mae: 381.8256 - val_loss: 425846.2188 - val_mae: 376.5485\n",
      "Epoch 93/100\n",
      "14070/14070 [==============================] - 11s 803us/step - loss: 428153.3750 - mae: 382.2167 - val_loss: 427746.5938 - val_mae: 382.7841\n",
      "Epoch 94/100\n",
      "14070/14070 [==============================] - 15s 1ms/step - loss: 428157.9062 - mae: 381.4276 - val_loss: 427626.1250 - val_mae: 377.7992\n",
      "Epoch 95/100\n",
      "14070/14070 [==============================] - 10s 741us/step - loss: 428890.0000 - mae: 381.9241 - val_loss: 431269.7500 - val_mae: 380.0273\n",
      "Epoch 96/100\n",
      "14070/14070 [==============================] - 10s 713us/step - loss: 427848.2188 - mae: 382.0388 - val_loss: 430942.1562 - val_mae: 379.0081\n",
      "Epoch 97/100\n",
      "14070/14070 [==============================] - 10s 731us/step - loss: 428571.4688 - mae: 381.6322 - val_loss: 433079.2500 - val_mae: 384.2211\n",
      "Epoch 98/100\n",
      "14070/14070 [==============================] - 10s 693us/step - loss: 427473.7812 - mae: 381.6122 - val_loss: 428154.3125 - val_mae: 377.9446\n",
      "Epoch 99/100\n",
      "14070/14070 [==============================] - 10s 687us/step - loss: 428891.0312 - mae: 381.7325 - val_loss: 427095.7500 - val_mae: 381.1398\n",
      "Epoch 100/100\n",
      "14070/14070 [==============================] - 10s 687us/step - loss: 427243.7188 - mae: 381.7060 - val_loss: 434972.7500 - val_mae: 386.2188\n",
      "INFO:tensorflow:Assets written to: PRICESTIANE1/assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer='adam', metrics=[\"mae\"])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.1)\n",
    "model.save('PRICESTIANE1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb944e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543/543 [==============================] - 0s 522us/step - loss: 547070.7500 - mae: 386.3384\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1deecd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c27c5e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1409.8866],\n",
       "       [2183.6187],\n",
       "       [6573.8193],\n",
       "       ...,\n",
       "       [5638.923 ],\n",
       "       [4918.429 ],\n",
       "       [4856.8457]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c197caaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9317516 ,  0.73486408, -0.30331921, ..., -0.9549836 ,\n",
       "        -0.91821669, -0.86380456],\n",
       "       [-0.88128974, -0.37158657,  0.32753115, ..., -0.82344429,\n",
       "        -0.78574418, -0.78341371],\n",
       "       [ 0.75832767, -0.37158657, -0.93416957, ...,  0.82834193,\n",
       "         0.84593844,  0.7875457 ],\n",
       "       ...,\n",
       "       [ 0.91655716, -0.37158657, -0.93416957, ...,  0.95785489,\n",
       "         0.88085361,  0.84833791],\n",
       "       [ 0.49598555,  1.84131473, -0.30331921, ...,  0.57047117,\n",
       "         0.48857766,  0.69385123],\n",
       "       [ 0.49497156,  0.73486408, -1.56501993, ...,  0.68167685,\n",
       "         0.72402635,  0.39434996]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34f5c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-87264841ac40>:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prediction[1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([inf], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(prediction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7de989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-89-26f2dce1918c>:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(y_test[1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a11d2621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1436., 2267., 5827., ..., 4666., 5518., 4251.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb496a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
